# =======================================================
# corrector.py
# å…ƒå­¦ä¹ ä¿®æ­£æ¨¡å—ï¼šæ ¹æ®æ‹“æ‰‘è¯Šæ–­ç»“æœæ‰§è¡Œç»“æ„ä¿®æ­£
# èŒè´£: åŒ…å«è°ƒæ•´æ­£åˆ™åŒ–æƒé‡ã€é‡ç½®è”ç»œå‚æ•°ç­‰å…³é”®æ“ä½œã€‚
# =======================================================

import torch
import torch.nn as nn
from typing import TYPE_CHECKING
import torch.optim as optim

# ä¸ºäº†é¿å…å¾ªç¯ä¾èµ–å’Œç®€åŒ–ç±»å‹æç¤ºï¼Œä½¿ç”¨ TYPE_CHECKING
if TYPE_CHECKING:
    from .transformer import TopologyAwareTransformer # å‡å®š Transformer ç±»å®šä¹‰åœ¨ transformer.py ä¸­

class TopologicalCorrector:
    """
    å…ƒå­¦ä¹ ä¿®æ­£å™¨ï¼šæ ¹æ®è¯Šæ–­çŠ¶æ€ (0, 1, 2) æ‰§è¡Œä¿®æ­£åŠ¨ä½œã€‚

    çŠ¶æ€å®šä¹‰:
    - 0: æ­£å¸¸ç³»ç»Ÿ
    - 1: å¼‚å¸¸ç³»ç»Ÿ (é«˜å±€éƒ¨æ›²ç‡/ç¦»ç¾¤å€¼ -> c2/c1 æ”¾å¤§)
    - 2: çº¦æŸè¿åç³»ç»Ÿ (å‡ ä½•ç»“æ„åˆšæ€§/é”å®š -> c1/c2 å€¼å¼‚å¸¸)
    """

    def __init__(self, model: 'TopologyAwareTransformer', optimizer: optim.Optimizer, initial_lambda: float = 0.01):
        """
        åˆå§‹åŒ–ä¿®æ­£å™¨ã€‚
        :param model: L1 å­¦ä¹ æ¨¡å‹ (TopologyAwareTransformer å®ä¾‹)
        :param optimizer: æ¨¡å‹çš„ä¼˜åŒ–å™¨
        :param initial_lambda: æ‹“æ‰‘æ­£åˆ™åŒ–é¡¹çš„åˆå§‹æƒé‡ (Î»)
        """
        self.model = model
        self.optimizer = optimizer
        self.initial_lambda = initial_lambda
        self.current_lambda = initial_lambda
        # å†»ç»“çŠ¶æ€æ ‡å¿—
        self.frozen_learning_rate = None

    def adjust_lambda(self, factor: float):
        """
        è°ƒæ•´æ‹“æ‰‘æ­£åˆ™åŒ–æƒé‡ (self.current_lambda)ã€‚
        :param factor: ä¹˜æ³•å› å­ (ä¾‹å¦‚ 2.0 å¢å¤§ï¼Œ0.5 å‡å°)
        """
        # ç¡®ä¿ Î» ä¸ä¼šä½äºä¸€ä¸ªå¾®å°å€¼
        self.current_lambda = max(self.initial_lambda * 0.01, self.current_lambda * factor)
        print(f"   [Corrector] è°ƒæ•´æ‹“æ‰‘æ­£åˆ™åŒ–æƒé‡ Î»: new_lambda = {self.current_lambda:.6f}")

    def reset_connection_forms(self, layer_index: int = 0):
        """
        æ‰“ç ´çº¦æŸï¼šé‡ç½®å…³é”®å±‚çš„è”ç»œå½¢å¼ A å‚æ•°ã€‚
        è¿™æ˜¯ä¸€ç§æ¿€è¿›çš„ä¿®æ­£ï¼Œç”¨äºæ‰“ç ´æ‹“æ‰‘å†»ç»“æˆ–çº¦æŸè¿åçŠ¶æ€ã€‚
        :param layer_index: è¦é‡ç½®çš„å±‚ç´¢å¼•ã€‚
        """
        if layer_index < len(self.model.layers):
            # è·å– ChernClassCalculator æ¨¡å—
            calc = self.model.layers[layer_index].chern_calculator

            # é‡ç½®è”ç»œå½¢å¼å‚æ•° A (connection_form) ä¸ºéšæœºå€¼
            # ä¿æŒåŸå§‹æ ‡å‡†å·®ï¼Œä»¥ä¿æŒåˆå§‹æ›²ç‡é‡çº§
            nn.init.normal_(calc.connection_form.data, mean=0., std=0.1)

            # å¯é€‰ï¼šé‡ç½®æ›²ç‡æƒé‡
            nn.init.normal_(calc.curvature_weight.data, mean=0., std=0.01)

            print(f"   [Corrector] ğŸš¨ æ¿€è¿›ä¿®æ­£: é‡ç½® Layer {layer_index} çš„è”ç»œå½¢å¼ (A)ã€‚")

    def temporary_freeze_lr(self, duration: float = 100):
        """
        æš‚æ—¶å†»ç»“ L1 ä»»åŠ¡çš„å­¦ä¹ ç‡ï¼Œå¼ºåˆ¶æ¨¡å‹é€šè¿‡æ‹“æ‰‘æ­£åˆ™åŒ–æ¥ä¿®æ­£ç»“æ„ã€‚
        :param duration: å†»ç»“çš„æ­¥æ•°æˆ–æ—¶é—´ã€‚
        """
        if self.frozen_learning_rate is None:
            # ä¿å­˜å½“å‰å­¦ä¹ ç‡å¹¶è®¾ç½®ä¸€ä¸ªéå¸¸å°çš„å€¼
            current_lr = self.optimizer.param_groups[0]['lr']
            self.frozen_learning_rate = current_lr
            self.optimizer.param_groups[0]['lr'] = current_lr * 0.01 # é™ä¸º 1%
            print(f"   [Corrector] å†»ç»“ LR: L1 ä»»åŠ¡å­¦ä¹ ç‡é™è‡³ {self.optimizer.param_groups[0]['lr']:.8f}")

    def unfreeze_lr(self):
        """
        è§£é™¤ L1 ä»»åŠ¡å­¦ä¹ ç‡çš„å†»ç»“ã€‚
        """
        if self.frozen_learning_rate is not None:
            self.optimizer.param_groups[0]['lr'] = self.frozen_learning_rate
            self.frozen_learning_rate = None
            print(f"   [Corrector] è§£é™¤å†»ç»“: L1 ä»»åŠ¡å­¦ä¹ ç‡æ¢å¤è‡³ {self.optimizer.param_groups[0]['lr']:.8f}")

    def execute_correction(self, predicted_state: int, topo_info: dict):
        """
        æ‰§è¡ŒåŸºäºè¯Šæ–­çŠ¶æ€çš„å…ƒå­¦ä¹ ä¿®æ­£ã€‚
        :param predicted_state: L2 è¯Šæ–­å™¨é¢„æµ‹çš„ç³»ç»ŸçŠ¶æ€ (0, 1, or 2)ã€‚
        """
        self.unfreeze_lr() # æ¯æ¬¡è¯Šæ–­å‰å°è¯•è§£é™¤å†»ç»“

        #avg_c1 = topo_info.get('first_chern_class_mean', 0.0)

        #if avg_c1 > 20.0:
          # æˆ‘ä»¬çŸ¥é“ 25.93 æ˜¯ä¸€ä¸ªé”å®šçš„çŠ¶æ€
          #predicted_state = 2
          #print(f"   [Corrector] ğŸš¨ ç¡¬è§¦å‘ï¼šå¹³å‡ c1 ({avg_c1:.2f}) è¶…è¿‡å®‰å…¨é˜ˆå€¼ 20.0ï¼Œå¼ºåˆ¶è¯Šæ–­ä¸ºçŠ¶æ€ 2ã€‚")

        HIGH_LAMBDA_THRESHOLD = 5.0 # å®šä¹‰æ™ºèƒ½è§¦å‘çš„é«˜é˜ˆå€¼ (å¯æ ¹æ®éœ€è¦è°ƒæ•´)

        #if predicted_state == 1: # å¦‚æœè¯Šæ–­å™¨é¢„æµ‹ä¸ºçŠ¶æ€ 1 (å¼‚å¸¸/é«˜æ›²ç‡)

          # æ£€æŸ¥å½“å‰ Î» æ˜¯å¦å·²è¶…è¿‡é«˜é˜ˆå€¼
          #if self.current_lambda > HIGH_LAMBDA_THRESHOLD:
            # Î» å·²ç»å¾ˆé«˜ï¼Œè¡¨æ˜æ¸©å’Œä¿®æ­£æ— æ•ˆï¼Œå¼ºåˆ¶è½¬ä¸ºçŠ¶æ€ 2 (æ¿€è¿›ä¿®æ­£)
            #predicted_state = 2
            #print(f"   [Corrector] ğŸ’¡ æ™ºèƒ½å‡çº§: è¯Šæ–­ä¸ºçŠ¶æ€ 1ï¼Œä½† Î» ({self.current_lambda:.4f}) > {HIGH_LAMBDA_THRESHOLD:.1f}ï¼Œå¼ºåˆ¶è½¬ä¸ºçŠ¶æ€ 2ã€‚")


        if predicted_state == 1:

            # çŠ¶æ€ 1: å¼‚å¸¸ç³»ç»Ÿ (é«˜å±€éƒ¨æ›²ç‡)
            # çŠ¶æ€ 1 ä¿®æ­£ï¼šåœ¨ Î» <= 5.0 æ—¶æ‰§è¡Œæ¸©å’Œä¿®æ­£
            print("   [Corrector] è¯Šæ–­ç»“æœ: çŠ¶æ€ 1 (å¼‚å¸¸/é«˜æ›²ç‡)ã€‚")
            # æªæ–½: 1. å¢åŠ æ­£åˆ™åŒ–åŠ›åº¦ä»¥å¹³æ»‘æµå½¢ï¼› 2. çŸ­æš‚å†»ç»“ LRï¼Œå¼ºè°ƒæ‹“æ‰‘ä¿®æ­£ã€‚
            self.adjust_lambda(factor=1.2) # æ¿€è¿›å¢åŠ  Î»
            #self.temporary_freeze_lr()

        elif predicted_state == 2:

            # çŠ¶æ€ 2: çº¦æŸè¿åç³»ç»Ÿ (ç»“æ„é”å®š/å‡ ä½•åˆšæ€§)
            print("   [Corrector] è¯Šæ–­ç»“æœ: çŠ¶æ€ 2 (çº¦æŸè¿å/é”å®š)ã€‚")
            # æªæ–½: 1. é‡ç½®è”ç»œæ‰“ç ´é”å®šï¼› 2. é™ä½ Î»ï¼Œç»™æ¨¡å‹é‡æ–°å­¦ä¹ å‡ ä½•ç»“æ„çš„ç©ºé—´ã€‚
            self.reset_connection_forms(layer_index=0) # ä¿®æ­£ç¬¬ä¸€å±‚
            self.adjust_lambda(factor=0.5) # å¤§å¹…é™ä½ Î»

        elif predicted_state == 0:
            # çŠ¶æ€ 0: æ­£å¸¸ç³»ç»Ÿ (å¥åº·)
            print("   [Corrector] è¯Šæ–­ç»“æœ: çŠ¶æ€ 0 (æ­£å¸¸/å¥åº·)ã€‚")
            # æªæ–½: ç¼“æ…¢æ¢å¤åˆ°åˆå§‹æ­£åˆ™åŒ–æƒé‡
            #if self.current_lambda > self.initial_lambda * 1.1:
                 #self.adjust_lambda(factor=0.8) # ç¼“æ…¢è¡°å‡ Î»
            #else:
                 #self.current_lambda = self.initial_lambda # ç¨³å®šåœ¨åˆå§‹å€¼
            
            if self.current_lambda > self.initial_lambda:# æªæ–½: è¿…é€Ÿæ¢å¤åˆ°åˆå§‹æ­£åˆ™åŒ–æƒé‡ (0.005)ï¼ŒL1 å­¦ä¹ ç‡ä¿æŒè§£é”
              self.current_lambda = self.initial_lambda
              print(" Â  [Corrector] æªæ–½: Î» æ¢å¤åˆ°åˆå§‹å€¼ã€‚")
            else:
              pass


        else:
            print(f"   [Corrector] è­¦å‘Š: æ— æ³•è¯†åˆ«çš„è¯Šæ–­çŠ¶æ€ {predicted_state}ã€‚æœªæ‰§è¡Œä¿®æ­£ã€‚")

        print(f"   [Corrector] è°ƒæ•´æ‹“æ‰‘æ­£åˆ™åŒ–æƒé‡ Î»: new_lambda = {self.current_lambda:.6f}") # æ·»åŠ æ–° Î» çš„è¾“å‡º


# =======================================================
# éªŒè¯ä»£ç  (åœ¨å®é™…éƒ¨ç½²ä¸­éœ€ Transformer å’Œ Optimizer å®ä¾‹)
# =======================================================
if __name__ == "__main__":


    # å ä½ç¬¦ç±»ï¼šæ¨¡æ‹Ÿ Transformer å’Œ Optimizer
    class MockLayer(nn.Module):
        def __init__(self, d):
            super().__init__()
            # æ¨¡æ‹Ÿ ChernClassCalculator çš„ connection_form å­˜åœ¨
            self.chern_calculator = type('MockCalc', (object,), {
                'connection_form': nn.Parameter(torch.randn(d, d) * 0.1),
                'curvature_weight': nn.Parameter(torch.randn(d, d) * 0.01)
            })()

    class MockTransformer:
        def __init__(self, d, L):
            self.layers = [MockLayer(d) for _ in range(L)]

    # 1. åˆå§‹åŒ–
    D_MODEL = 16
    mock_model = MockTransformer(D_MODEL, L=4)
    mock_optimizer = optim.Adam([p for l in mock_model.layers for p in [l.chern_calculator.connection_form, l.chern_calculator.curvature_weight]], lr=1e-4)

    corrector = TopologicalCorrector(mock_model, mock_optimizer, initial_lambda=0.01)

    print(f"åˆå§‹ Î»: {corrector.current_lambda}")
    print(f"åˆå§‹ LR: {corrector.optimizer.param_groups[0]['lr']}")

    # æ¨¡æ‹Ÿä¸€ä¸ªæ‹“æ‰‘ä¿¡æ¯å­—å…¸
    # çŠ¶æ€ 1 æ¨¡æ‹Ÿï¼ˆc1 å‡å€¼æ­£å¸¸ï¼‰
    simulated_topo_info_normal = {'first_chern_class_mean': 0.4}
    # çŠ¶æ€ 2/é”å®šæ¨¡æ‹Ÿï¼ˆc1 å‡å€¼æé«˜ï¼Œç”¨äºè§¦å‘ç¡¬ä¿®æ­£ï¼‰
    simulated_topo_info_locked = {'first_chern_class_mean': 25.0}


    # 2. æ¨¡æ‹Ÿ çŠ¶æ€ 1 (å¼‚å¸¸)
    print("\n--- æ¨¡æ‹Ÿè¯Šæ–­çŠ¶æ€ 1 (å¼‚å¸¸) ---")
    corrector.execute_correction(1, simulated_topo_info_normal)
    print(f"ä¿®æ­£å Î»: {corrector.current_lambda:.6f}")
    print(f"ä¿®æ­£å LR: {corrector.optimizer.param_groups[0]['lr']:.8f}") # åº”è¯¥è¢«å†»ç»“

    # 3. æ¨¡æ‹Ÿ çŠ¶æ€ 2 (çº¦æŸè¿å)
    print("\n--- æ¨¡æ‹Ÿè¯Šæ–­çŠ¶æ€ 2 (çº¦æŸè¿å) ---")
    # è·å–é‡ç½®å‰çš„ connection_form (Layer 0)
    old_conn = mock_model.layers[0].chern_calculator.connection_form.data.clone().mean().item()
    print(f"Layer 0 A å‡å€¼ (é‡ç½®å‰): {old_conn:.4f}")

    corrector.execute_correction(2, simulated_topo_info_locked)
    new_conn = mock_model.layers[0].chern_calculator.connection_form.data.mean().item()

    print(f"Layer 0 A å‡å€¼ (é‡ç½®å): {new_conn:.4f} (åº”å˜åŒ–)")
    print(f"ä¿®æ­£å Î»: {corrector.current_lambda:.6f}") # åº”è¯¥å¤§å¹…é™ä½
    print(f"ä¿®æ­£å LR: {corrector.optimizer.param_groups[0]['lr']:.8f}") # åº”è¯¥è§£é™¤å†»ç»“

    # 4. æ¨¡æ‹Ÿ çŠ¶æ€ 0 (æ­£å¸¸)
    print("\n--- æ¨¡æ‹Ÿè¯Šæ–­çŠ¶æ€ 0 (æ­£å¸¸) ---")
    corrector.execute_correction(0, simulated_topo_info_normal)
    print(f"ä¿®æ­£å Î»: {corrector.current_lambda:.6f}") # åº”è¯¥æ¢å¤åˆ°åˆå§‹ Î» æˆ–ç•¥é«˜äºåˆå§‹ Î»
