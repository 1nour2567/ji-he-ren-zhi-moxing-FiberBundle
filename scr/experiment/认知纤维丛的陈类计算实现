import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import math

class CognitiveFiberBundle(nn.Module):
    """è®¤çŸ¥çº¤ç»´ä¸›æ¨¡å‹ - é™ˆç±»è®¡ç®—çš„æœ€ç»ˆå®ç°"""
    def __init__(self, vocab_size, d_model=64, k_neighbors=8):
        super().__init__()
        self.vocab_size = vocab_size
        self.d_model = d_model
        self.k_neighbors = k_neighbors
        
        # å­˜å‚¨ä¸­é—´æ¿€æ´»å€¼ç”¨äºé™ˆç±»è®¡ç®—
        self.activations = {}
        
        # è®¤çŸ¥çº¤ç»´ä¸›çš„è”ç»œå½¢å¼ï¼ˆconnection formï¼‰
        self.connection_form = nn.Parameter(torch.randn(d_model, d_model) * 0.1)
        
        # ç®€åŒ–çš„æ›²ç‡å½¢å¼è®¡ç®—å‚æ•°
        self.curvature_weight = nn.Parameter(torch.randn(d_model, d_model) * 0.01)
        
        # å‡ ä½•ç¼–ç å±‚
        self.geometric_layers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_model, d_model),
                nn.GELU()
            ),
            nn.Sequential(
                nn.Linear(d_model, d_model),
                nn.GELU()
            )
        ])
    
    def compute_connection_form(self, x):
        """è®¡ç®—è”ç»œå½¢å¼ A - ä¿®å¤ç‰ˆæœ¬"""
        batch_size, n, d = x.shape
        x_flat = x.view(batch_size * n, d)
        
        # æ‰©å±•connection_formåˆ°batchç»´åº¦
        connection = self.connection_form.unsqueeze(0).expand(batch_size * n, -1, -1)
        
        # ç®€åŒ–ï¼šä¸ºæ¯ä¸ªä½ç½®æ·»åŠ åŸºäºè¾“å…¥çš„å¯¹è§’æ‰°åŠ¨
        input_diag = torch.diag_embed(torch.mean(x_flat, dim=1, keepdim=True).expand(-1, d) * 0.01)
        connection = connection + input_diag
        
        return connection
    
    def compute_curvature_form(self, connection):
        """è®¡ç®—æ›²ç‡å½¢å¼ F = dA + Aâˆ§A (ç®€åŒ–ç‰ˆæœ¬)"""
        batch_size_n, d, d = connection.shape
        
        # ç®€åŒ–ç‰ˆæœ¬ï¼šF = A*A - A^T*A (ææ‹¬å·çš„å¯¹è§’å ä¼˜è¿‘ä¼¼)
        A_squared = torch.bmm(connection, connection)
        A_transposed = connection.transpose(-2, -1)
        A_transposed_squared = torch.bmm(A_transposed, connection)
        
        curvature = A_squared - A_transposed_squared
        return curvature
    
    def compute_chern_class(self, curvature):
        """è®¡ç®—é™ˆç±» - æ‹“æ‰‘ä¸å˜é‡"""
        batch_size, d, d = curvature.shape
        
        # ç¬¬ä¸€é™ˆç±»: c1 = tr(F) / (2Ï€i)
        trace_F = torch.diagonal(curvature, dim1=-2, dim2=-1).sum(dim=-1)  # tr(F)
        first_chern_class = trace_F / (2 * math.pi * 1j)  # å¤æ•°å½¢å¼
        
        # ç¬¬äºŒé™ˆç±»: c2 = (tr(FÂ²) - tr(F)Â²) / (8Ï€Â²)
        F_squared = torch.bmm(curvature, curvature)
        trace_F_squared = torch.diagonal(F_squared, dim1=-2, dim2=-1).sum(dim=-1)  # tr(FÂ²)
        
        second_chern_class = (trace_F_squared - trace_F**2) / (8 * math.pi**2)
        
        return {
            'first_chern_class': first_chern_class.real,  # å–å®éƒ¨
            'second_chern_class': second_chern_class,
            'trace_F': trace_F,
            'trace_F_squared': trace_F_squared
        }
    
    def compute_topological_invariants(self, x):
        """è®¡ç®—æ‹“æ‰‘ä¸å˜é‡ - ä¿®å¤ç‰ˆæœ¬"""
        batch_size, n, d = x.shape
        all_invariants = {'first_chern_class': [], 'second_chern_class': [], 
                         'trace_F': [], 'trace_F_squared': []}
        
        for i in range(n):
            x_slice = x[:, i:i+1, :]  # [batch_size, 1, d_model]
            x_slice_expanded = x_slice.expand(-1, d, -1)  # [batch_size, d, d_model]
            
            connection = self.compute_connection_form(x_slice)
            curvature = self.compute_curvature_form(connection)
            chern_classes = self.compute_chern_class(curvature)
            
            all_invariants['first_chern_class'].append(chern_classes['first_chern_class'])
            all_invariants['second_chern_class'].append(chern_classes['second_chern_class'])
            all_invariants['trace_F'].append(chern_classes['trace_F'])
            all_invariants['trace_F_squared'].append(chern_classes['trace_F_squared'])
        
        # åˆå¹¶æ‰€æœ‰ä½ç½®çš„ç»“æœ
        result = {}
        for key in all_invariants:
            if all_invariants[key]:  # ç¡®ä¿åˆ—è¡¨ä¸ä¸ºç©º
                result[key] = torch.stack(all_invariants[key], dim=1)
            else:
                # å¦‚æœä¸ºç©ºï¼Œåˆ›å»ºé€‚å½“å½¢çŠ¶çš„é›¶å¼ é‡
                result[key] = torch.zeros(batch_size, n, dtype=torch.float32, device=x.device)
        
        return result
    
    def forward(self, x):
        """x: [batch_size, vocab_size, d_model]"""
        batch_size, n, d = x.shape
        
        # ä¿å­˜è¾“å…¥ç”¨äºé™ˆç±»è®¡ç®—
        self.activations['input'] = x.clone()
        self.activations['input_topology'] = self.compute_topological_invariants(x)
        
        # åº”ç”¨å‡ ä½•å˜æ¢
        x_flat = x.view(-1, d)
        for i, layer in enumerate(self.geometric_layers):
            x_flat = layer(x_flat)
            layer_output = x_flat.view(batch_size, n, d)
            
            self.activations[f'layer{i+1}'] = layer_output.clone()
            self.activations[f'layer{i+1}_topology'] = self.compute_topological_invariants(layer_output)
        
        x = x_flat.view(batch_size, n, d)
        self.activations['output'] = x.clone()
        self.activations['output_topology'] = self.compute_topological_invariants(x)
        
        return x

class ChernClassAnalyzer:
    """é™ˆç±»åˆ†æå™¨"""
    def __init__(self, model):
        self.model = model
        self.chern_history = []
    
    def analyze_chern_classes(self):
        """åˆ†æå„å±‚çš„é™ˆç±»"""
        topology_keys = [k for k in self.model.activations.keys() if 'topology' in k]
        
        chern_analysis = {}
        
        for key in topology_keys:
            topo_info = self.model.activations[key]
            
            chern_analysis[key] = {
                'first_chern_mean': torch.mean(topo_info['first_chern_class']).item(),
                'first_chern_std': torch.std(topo_info['first_chern_class']).item(),
                'second_chern_mean': torch.mean(topo_info['second_chern_class']).item(),
                'second_chern_std': torch.std(topo_info['second_chern_class']).item(),
                'trace_F_mean': torch.mean(topo_info['trace_F']).item(),
                'trace_F_std': torch.std(topo_info['trace_F']).item()
            }
        
        return chern_analysis
    
    def detect_topological_phase_transitions(self):
        """æ£€æµ‹æ‹“æ‰‘ç›¸å˜ï¼ˆé™ˆç±»çš„çªå˜ï¼‰"""
        topology_keys = [k for k in self.model.activations.keys() if 'topology' in k]
        
        phase_transitions = []
        
        for i in range(len(topology_keys)-1):
            current_key = topology_keys[i]
            next_key = topology_keys[i+1]
            
            current_chern = self.model.activations[current_key]
            next_chern = self.model.activations[next_key]
            
            # è®¡ç®—é™ˆç±»å˜åŒ–
            first_chern_change = torch.mean(torch.abs(
                torch.mean(current_chern['first_chern_class'], dim=[0,1]) - 
                torch.mean(next_chern['first_chern_class'], dim=[0,1])
            )).item()
            
            second_chern_change = torch.mean(torch.abs(
                torch.mean(current_chern['second_chern_class'], dim=[0,1]) - 
                torch.mean(next_chern['second_chern_class'], dim=[0,1])
            )).item()
            
            # å¦‚æœé™ˆç±»å˜åŒ–è¶…è¿‡é˜ˆå€¼ï¼Œè®¤ä¸ºæ˜¯æ‹“æ‰‘ç›¸å˜
            if first_chern_change > 0.1 or second_chern_change > 0.01:
                phase_transitions.append({
                    'transition': f"{current_key} -> {next_key}",
                    'first_chern_change': first_chern_change,
                    'second_chern_change': second_chern_change,
                    'detected': True
                })
        
        return phase_transitions

def visualize_chern_classes():
    """å¯è§†åŒ–é™ˆç±»è®¡ç®—ç»“æœ"""
    # æ¨¡æ‹Ÿæ•°æ®
    batch_size = 1
    vocab_size = 8
    d_model = 16  # å‡å°ç»´åº¦ä»¥ç®€åŒ–è®¡ç®—
    
    # åˆ›å»ºæ¨¡å‹
    model = CognitiveFiberBundle(vocab_size, d_model=d_model)
    analyzer = ChernClassAnalyzer(model)
    
    # åˆ›å»ºè¾“å…¥
    inputs = torch.randn(batch_size, vocab_size, d_model)
    
    # å‰å‘ä¼ æ’­
    outputs = model(inputs)
    
    # åˆ†æé™ˆç±»
    chern_analysis = analyzer.analyze_chern_classes()
    phase_transitions = analyzer.detect_topological_phase_transitions()
    
    print("ğŸ” é™ˆç±»è®¡ç®—ç»“æœ:")
    for layer, chern_info in chern_analysis.items():
        print(f"  {layer}:")
        print(f"    ç¬¬ä¸€é™ˆç±»å‡å€¼: {chern_info['first_chern_mean']:.6f}")
        print(f"    ç¬¬ä¸€é™ˆç±»æ ‡å‡†å·®: {chern_info['first_chern_std']:.6f}")
        print(f"    ç¬¬äºŒé™ˆç±»å‡å€¼: {chern_info['second_chern_mean']:.6f}")
        print(f"    ç¬¬äºŒé™ˆç±»æ ‡å‡†å·®: {chern_info['second_chern_std']:.6f}")
    
    if phase_transitions:
        print(f"\nğŸ”„ æ£€æµ‹åˆ°æ‹“æ‰‘ç›¸å˜: {len(phase_transitions)}ä¸ª")
        for i, trans in enumerate(phase_transitions):
            print(f"  [{i+1}] {trans['transition']}")
            print(f"      ç¬¬ä¸€é™ˆç±»å˜åŒ–: {trans['first_chern_change']:.6f}")
            print(f"      ç¬¬äºŒé™ˆç±»å˜åŒ–: {trans['second_chern_change']:.6f}")
    else:
        print(f"\nğŸ”„ æœªæ£€æµ‹åˆ°æ‹“æ‰‘ç›¸å˜")
    
    # å¯è§†åŒ–
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()
    
    # é™ˆç±»å˜åŒ–è¶‹åŠ¿
    layers = list(chern_analysis.keys())
    first_chern_means = [chern_analysis[layer]['first_chern_mean'] for layer in layers]
    second_chern_means = [chern_analysis[layer]['second_chern_mean'] for layer in layers]
    
    axes[0].plot(range(len(layers)), first_chern_means, 'ro-', linewidth=2, markersize=8, label='ç¬¬ä¸€é™ˆç±»')
    axes[0].set_title('ç¬¬ä¸€é™ˆç±»æ²¿ç½‘ç»œçš„å˜åŒ–', fontsize=12)
    axes[0].set_xlabel('ç½‘ç»œå±‚')
    axes[0].set_ylabel('ç¬¬ä¸€é™ˆç±»å‡å€¼')
    axes[0].set_xticks(range(len(layers)))
    axes[0].set_xticklabels([layer.replace('_topology', '') for layer in layers], rotation=45)
    axes[0].grid(True, alpha=0.3)
    axes[0].legend()
    
    axes[1].plot(range(len(layers)), second_chern_means, 'bo-', linewidth=2, markersize=8, label='ç¬¬äºŒé™ˆç±»')
    axes[1].set_title('ç¬¬äºŒé™ˆç±»æ²¿ç½‘ç»œçš„å˜åŒ–', fontsize=12)
    axes[1].set_xlabel('ç½‘ç»œå±‚')
    axes[1].set_ylabel('ç¬¬äºŒé™ˆç±»å‡å€¼')
    axes[1].set_xticks(range(len(layers)))
    axes[1].set_xticklabels([layer.replace('_topology', '') for layer in layers], rotation=45)
    axes[1].grid(True, alpha=0.3)
    axes[1].legend()
    
    # é™ˆç±»åˆ†å¸ƒç›´æ–¹å›¾
    input_chern = model.activations['input_topology']
    output_chern = model.activations['output_topology']
    
    axes[2].hist(input_chern['first_chern_class'].detach().numpy().flatten(), bins=20, alpha=0.7, 
                 color='red', label='è¾“å…¥å±‚', edgecolor='black')
    axes[2].hist(output_chern['first_chern_class'].detach().numpy().flatten(), bins=20, alpha=0.7, 
                 color='blue', label='è¾“å‡ºå±‚', edgecolor='black')
    axes[2].set_title('ç¬¬ä¸€é™ˆç±»åˆ†å¸ƒå¯¹æ¯”', fontsize=12)
    axes[2].set_xlabel('ç¬¬ä¸€é™ˆç±»å€¼')
    axes[2].set_ylabel('é¢‘æ¬¡')
    axes[2].legend()
    
    axes[3].hist(input_chern['second_chern_class'].detach().numpy().flatten(), bins=20, alpha=0.7, 
                 color='red', label='è¾“å…¥å±‚', edgecolor='black')
    axes[3].hist(output_chern['second_chern_class'].detach().numpy().flatten(), bins=20, alpha=0.7, 
                 color='blue', label='è¾“å‡ºå±‚', edgecolor='black')
    axes[3].set_title('ç¬¬äºŒé™ˆç±»åˆ†å¸ƒå¯¹æ¯”', fontsize=12)
    axes[3].set_xlabel('ç¬¬äºŒé™ˆç±»å€¼')
    axes[3].set_ylabel('é¢‘æ¬¡')
    axes[3].legend()
    
    # æ›²ç‡è¿¹å˜åŒ–
    input_trace = input_chern['trace_F']
    output_trace = output_chern['trace_F']
    
    trace_layers = ['è¾“å…¥å±‚', 'å±‚1', 'å±‚2', 'è¾“å‡ºå±‚']
    trace_values = [
        torch.mean(input_chern['trace_F']).item(),
        torch.mean(model.activations['layer1_topology']['trace_F']).item(),
        torch.mean(model.activations['layer2_topology']['trace_F']).item(),
        torch.mean(output_chern['trace_F']).item()
    ]
    
    axes[4].bar(trace_layers, trace_values, color=['red', 'orange', 'lightblue', 'blue'], alpha=0.7)
    axes[4].set_title('æ›²ç‡è¿¹ï¼ˆtrace Fï¼‰æ²¿ç½‘ç»œçš„å˜åŒ–', fontsize=12)
    axes[4].set_xlabel('ç½‘ç»œå±‚')
    axes[4].set_ylabel('æ›²ç‡è¿¹å‡å€¼')
    axes[4].tick_params(axis='x', rotation=45)
    
    # æ‹“æ‰‘ç¨³å®šæ€§è¯„ä¼°
    if phase_transitions:
        transition_layers = [trans['transition'] for trans in phase_transitions]
        first_changes = [trans['first_chern_change'] for trans in phase_transitions]
        second_changes = [trans['second_chern_change'] for trans in phase_transitions]
        
        x_pos = np.arange(len(transition_layers))
        width = 0.35
        
        axes[5].bar(x_pos - width/2, first_changes, width, label='ç¬¬ä¸€é™ˆç±»å˜åŒ–', alpha=0.7, color='red')
        axes[5].bar(x_pos + width/2, second_changes, width, label='ç¬¬äºŒé™ˆç±»å˜åŒ–', alpha=0.7, color='blue')
        axes[5].set_title('æ‹“æ‰‘ç›¸å˜å¼ºåº¦', fontsize=12)
        axes[5].set_xlabel('ç›¸å˜ä½ç½®')
        axes[5].set_ylabel('é™ˆç±»å˜åŒ–é‡')
        axes[5].set_xticks(x_pos)
        axes[5].set_xticklabels([t.split(' -> ')[1] for t in transition_layers], rotation=45)
        axes[5].legend()
    else:
        axes[5].text(0.5, 0.5, 'âœ… æœªæ£€æµ‹åˆ°\næ‹“æ‰‘ç›¸å˜', 
                    horizontalalignment='center', verticalalignment='center',
                    transform=axes[5].transAxes, fontsize=14,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
        axes[5].set_title('æ‹“æ‰‘ç›¸å˜æ£€æµ‹', fontsize=12)
        axes[5].set_xlim(0, 1)
        axes[5].set_ylim(0, 1)
    
    plt.tight_layout()
    plt.show()
    
    # ç†è®ºæ„ä¹‰æ€»ç»“
    print(f"\nğŸ¯ é™ˆç±»è®¡ç®—çš„ç†è®ºæ„ä¹‰:")
    print(f"  â€¢ ç¬¬ä¸€é™ˆç±»åæ˜ äº†è®¤çŸ¥çº¤ç»´ä¸›çš„'æ‰­æ›²ç¨‹åº¦'")
    print(f"  â€¢ ç¬¬äºŒé™ˆç±»åæ˜ äº†è®¤çŸ¥çº¤ç»´ä¸›çš„'å¤æ‚æ€§'") 
    print(f"  â€¢ æ‹“æ‰‘ç›¸å˜è¡¨ç¤ºè®¤çŸ¥ç»“æ„çš„æ ¹æœ¬æ€§æ”¹å˜")
    print(f"  â€¢ é™ˆç±»ä¸ºè®¤çŸ¥ç³»ç»Ÿçš„æ‹“æ‰‘æ€§è´¨æä¾›äº†å®šé‡æè¿°")
    print(f"  â€¢ éªŒè¯äº†è®¤çŸ¥çº¤ç»´ä¸›ç†è®ºçš„æ•°å­¦é¢„æµ‹")

# è¿è¡Œé™ˆç±»è®¡ç®—
if __name__ == "__main__":
    visualize_chern_classes()
