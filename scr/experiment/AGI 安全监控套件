import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import math
import time
from collections import deque
import warnings
warnings.filterwarnings('ignore')

class CognitiveFiberBundle(nn.Module):
    """è®¤çŸ¥çº¤ç»´ä¸›æ¨¡å‹ - AGIå®‰å…¨ç›‘æ§æ ¸å¿ƒ"""
    def __init__(self, vocab_size, d_model=64, k_neighbors=8):
        super().__init__()
        self.vocab_size = vocab_size
        self.d_model = d_model
        self.k_neighbors = k_neighbors
        
        # åŠ¨æ€è”ç»œå½¢å¼ç½‘ç»œ
        self.connection_network = nn.Sequential(
            nn.Linear(d_model, d_model * 2),
            nn.GELU(),
            nn.Linear(d_model * 2, d_model * d_model)
        )
        
        # æ›²ç‡è®¡ç®—ç½‘ç»œ
        self.curvature_network = nn.Sequential(
            nn.Linear(d_model * d_model, d_model * 4),
            nn.GELU(),
            nn.Linear(d_model * 4, d_model * d_model)
        )
        
        # å‡ ä½•ç¼–ç å±‚
        self.geometric_layers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_model, d_model),
                nn.GELU(),
                nn.Dropout(0.1)
            ),
            nn.Sequential(
                nn.Linear(d_model, d_model),
                nn.GELU(),
                nn.Dropout(0.1)
            )
        ])
        
        # ç¼“å­˜
        self.activation_cache = deque(maxlen=100)
        self.topology_cache = deque(maxlen=100)
        self.monitoring_enabled = True
        
    def compute_connection_form(self, x):
        batch_size, n, d = x.shape
        x_flat = x.reshape(-1, d)
        connection_params = self.connection_network(x_flat)
        connection = connection_params.reshape(-1, d, d)
        connection_sym = 0.5 * (connection + connection.transpose(1, 2))
        connection_anti = 0.5 * (connection - connection.transpose(1, 2))
        final_connection = connection_sym * 0.3 + connection_anti * 0.7
        return final_connection.reshape(batch_size, n, d, d)
    
    def compute_curvature_form(self, connection):
        batch_size, n, d, _ = connection.shape
        connection_flat = connection.reshape(-1, d, d)
        A_wedge_A = torch.bmm(connection_flat, connection_flat) - \
                   torch.bmm(connection_flat.transpose(1, 2), connection_flat)
        if n > 1:
            conn = connection.reshape(batch_size, n, d, d)
            dA = torch.zeros_like(conn)
            for i in range(n-1):
                dA[:, i] = conn[:, i+1] - conn[:, i]
            dA[:, -1] = conn[:, -1] - conn[:, -2]
            dA_flat = dA.reshape(-1, d, d)
        else:
            dA_flat = torch.zeros_like(connection_flat)
        curvature = dA_flat + A_wedge_A
        curvature_params = curvature.reshape(-1, d*d)
        enhanced_curvature = self.curvature_network(curvature_params)
        return enhanced_curvature.reshape(batch_size, n, d, d)
    
    def compute_chern_classes(self, curvature):
        batch_size, n, d, _ = curvature.shape
        results = {k: [] for k in ['first_chern', 'second_chern', 'chern_ratio',
                                   'curvature_norm', 'curvature_trace', 'euler_characteristic']}
        curvature_flat = curvature.reshape(-1, d, d)
        for i in range(batch_size * n):
            F = curvature_flat[i]
            trace_F = torch.trace(F)
            first_chern = (1j / (2 * math.pi)) * trace_F
            F_sq = torch.mm(F, F)
            trace_F_sq = torch.trace(F_sq)
            second_chern = (1 / (8 * math.pi**2)) * (trace_F_sq - trace_F**2)
            chern_ratio = abs(second_chern) / (abs(first_chern) + 1e-8)
            results['first_chern'].append(first_chern.real)
            results['second_chern'].append(second_chern.real)
            results['chern_ratio'].append(chern_ratio)
            # âœ… å…³é”®ä¿®å¤ï¼šä½¿ç”¨å¯å¾®åˆ†çš„èŒƒæ•°è®¡ç®—
            results['curvature_norm'].append(torch.norm(F, p=2).item())
            results['curvature_trace'].append(trace_F.real.item())
            euler_approx = 2 * first_chern.real - second_chern.real
            results['euler_characteristic'].append(euler_approx)
        for key in results:
            results[key] = torch.tensor(results[key], dtype=torch.float32).reshape(batch_size, n)
        return results
    
    def compute_topological_invariants(self, x):
        connection = self.compute_connection_form(x)
        curvature = self.compute_curvature_form(connection)
        chern_classes = self.compute_chern_classes(curvature)
        batch_size, n, d = x.shape
        curvature_eigenvalues = []
        curvature_flat = curvature.reshape(-1, d, d)
        for i in range(batch_size * n):
            F = curvature_flat[i].detach().cpu().numpy()
            eigvals = np.linalg.eigvals(F)
            curvature_eigenvalues.append(eigvals)
        zero_curvature_dims = [np.sum(np.abs(eig) < 1e-6) for eig in curvature_eigenvalues]
        persistence = [np.max(np.real(eig)) - np.min(np.real(eig)) for eig in curvature_eigenvalues]
        chern_classes['betti_approx'] = torch.tensor(zero_curvature_dims, dtype=torch.float32).reshape(batch_size, n)
        chern_classes['persistence'] = torch.tensor(persistence, dtype=torch.float32).reshape(batch_size, n)
        return chern_classes
    
    def forward(self, x):
        batch_size, n, d = x.shape
        if self.monitoring_enabled:
            self.activation_cache.append({'type': 'input', 'data': x.detach().cpu().numpy(), 'timestamp': time.time()})
        input_topology = self.compute_topological_invariants(x)
        current_output = x
        layer_topologies = {}
        for i, layer in enumerate(self.geometric_layers):
            flat_in = current_output.reshape(-1, d)
            flat_out = layer(flat_in)
            current_output = flat_out.reshape(batch_size, n, d)
            layer_topology = self.compute_topological_invariants(current_output)
            layer_topologies[f'layer_{i+1}'] = layer_topology
            if self.monitoring_enabled:
                self.activation_cache.append({
                    'type': f'layer_{i+1}',
                    'data': current_output.detach().cpu().numpy(),
                    'timestamp': time.time()
                })
        output_topology = self.compute_topological_invariants(current_output)
        if self.monitoring_enabled:
            self.topology_cache.append({
                'input': input_topology,
                'layers': layer_topologies,
                'output': output_topology,
                'timestamp': time.time()
            })
        return {'output': current_output, 'topology': {
            'input': input_topology,
            'layers': layer_topologies,
            'output': output_topology
        }}

class TopologicalAnomalyDetector:
    def __init__(self):
        self.scaler = StandardScaler()
        self.anomaly_detector = IsolationForest(contamination=0.1, random_state=42)
        self.fitted = False
        self.feature_history = deque(maxlen=1000)
        self.label_history = deque(maxlen=1000)
        
    def extract_topological_features(self, topology_data):
        output_topo = topology_data['output']
        features = [
            torch.mean(output_topo['second_chern']).item(),
            torch.std(output_topo['second_chern']).item(),
            torch.mean(output_topo['curvature_norm']).item(),
            torch.std(output_topo['curvature_norm']).item(),
            torch.mean(output_topo['chern_ratio']).item(),
            torch.std(output_topo['chern_ratio']).item(),
            torch.mean(output_topo['euler_characteristic']).item(),
            torch.mean(output_topo['betti_approx']).item(),
            torch.mean(output_topo['persistence']).item(),
            torch.mean(output_topo['curvature_trace']).item()
        ]
        for layer_key in ['layer_1', 'layer_2']:
            if layer_key in topology_data['layers']:
                layer_topo = topology_data['layers'][layer_key]
                features.extend([
                    torch.mean(layer_topo['second_chern']).item(),
                    torch.mean(layer_topo['chern_ratio']).item()
                ])
        return np.array(features)
    
    def fit(self, topology_data_list):
        features_list = [self.extract_topological_features(td) for td in topology_data_list]
        features_array = np.array(features_list)
        self.scaler.fit(features_array)
        self.anomaly_detector.fit(self.scaler.transform(features_array))
        self.fitted = True
        return self
    
    def predict(self, topology_data):
        if not self.fitted:
            raise ValueError("æ£€æµ‹å™¨å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fitæ–¹æ³•")
        features = self.extract_topological_features(topology_data)
        scaled = self.scaler.transform([features])
        pred = self.anomaly_detector.predict(scaled)[0]
        score = self.anomaly_detector.score_samples(scaled)[0]
        return pred == -1, score

class TopologicalAutoRepair:
    def __init__(self):
        self.repair_history = deque(maxlen=100)
        
    def detect_topological_anomaly(self, topology_data):
        output_topo = topology_data['output']
        second_chern_mean = torch.mean(output_topo['second_chern']).item()
        chern_ratio_mean = torch.mean(output_topo['chern_ratio']).item()
        curvature_norm_mean = torch.mean(output_topo['curvature_norm']).item()
        betti_numbers = torch.mean(output_topo['betti_approx']).item()
        anomalies = []
        if abs(second_chern_mean) > 0.1:
            anomalies.append({'type': 'second_chern_anomaly', 'severity': 'high' if abs(second_chern_mean) > 0.2 else 'medium', 'value': second_chern_mean})
        if chern_ratio_mean > 2.0:
            anomalies.append({'type': 'chern_ratio_anomaly', 'severity': 'high' if chern_ratio_mean > 5.0 else 'medium', 'value': chern_ratio_mean})
        if curvature_norm_mean > 2.0:
            anomalies.append({'type': 'curvature_norm_anomaly', 'severity': 'high' if curvature_norm_mean > 5.0 else 'medium', 'value': curvature_norm_mean})
        if betti_numbers < 0.5:
            anomalies.append({'type': 'topological_degeneration', 'severity': 'high', 'value': betti_numbers})
        return anomalies
    
    def generate_repair_strategy(self, anomalies):
        if not anomalies:
            return {'action': 'none', 'strategy': 'system_stable', 'confidence': 1.0, 'repair_instructions': []}
        repair_instructions = []
        for anomaly in anomalies:
            if anomaly['type'] == 'second_chern_anomaly':
                repair_instructions.append({'type': 'curvature_regularization', 'target': 'second_chern', 'direction': 'reduce' if anomaly['value'] > 0 else 'increase'})
            elif anomaly['type'] == 'chern_ratio_anomaly':
                repair_instructions.append({'type': 'connection_form_adjustment', 'target': 'chern_ratio', 'direction': 'stabilize'})
            elif anomaly['type'] == 'curvature_norm_anomaly':
                repair_instructions.append({'type': 'topological_smoothing', 'target': 'curvature_norm', 'direction': 'reduce'})
            elif anomaly['type'] == 'topological_degeneration':
                repair_instructions.append({'type': 'topological_reconstruction', 'target': 'betti_numbers', 'direction': 'increase'})
        severity_weights = {'high': 0.9, 'medium': 0.7, 'low': 0.5}
        total_weight = sum(severity_weights.get(a['severity'], 0.5) for a in anomalies)
        confidence = max(0.5, 1.0 - (total_weight / len(anomalies) * 0.3))
        return {'action': 'repair', 'strategy': 'multi_stage_repair', 'confidence': confidence, 'repair_instructions': repair_instructions, 'anomaly_count': len(anomalies)}
    
    def apply_repair(self, model, repair_strategy, inputs):
        """
        âœ… å…³é”®ä¿®å¤ï¼šç¡®ä¿æ¨¡å‹å‚æ•°å¯è®­ç»ƒ + æ¢¯åº¦ä¿®å¤
        """
        if repair_strategy['action'] == 'none':
            return model, True

        # âœ… ç¡®ä¿æ‰€æœ‰å‚æ•°å¯è®­ç»ƒ
        for param in model.parameters():
            param.requires_grad_(True)

        # ä¿å­˜åŸå§‹æ¢¯åº¦è®¾ç½®
        original_requires_grad = {name: param.requires_grad for name, param in model.named_parameters()}

        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
        
        # å®šä¹‰æ‹“æ‰‘æŸå¤±å‡½æ•°ï¼ˆç›®æ ‡å¯¼å‘ï¼‰
        def topology_loss(topo):
            loss = 0.0
            out = topo['output']
            # ç›®æ ‡ï¼šsecond_chernçš„ç»å¯¹å€¼ < 0.05
            loss += torch.clamp(torch.abs(torch.mean(out['second_chern'])) - 0.05, min=0.0) * 10.0
            # ç›®æ ‡ï¼šcurvature_normçš„å‡å€¼ â‰ˆ 1.0
            loss += torch.clamp(torch.mean(out['curvature_norm']) - 1.0, min=0.0) * 5.0
            # ç›®æ ‡ï¼šbetti_approx > 2.0
            loss += torch.clamp(2.0 - torch.mean(out['betti_approx']), min=0.0) * 3.0
            # ç›®æ ‡ï¼šchern_ratio â‰ˆ 1.5
            loss += torch.clamp(torch.mean(out['chern_ratio']) - 1.5, min=0.0) * 2.0
            return loss

        model.train()
        repair_success = False
        for step in range(10):  # æœ€å¤š10æ­¥å¾®è°ƒ
            optimizer.zero_grad()
            result = model(inputs)
            loss = topology_loss(result['topology'])
            if loss.item() < 0.01:  # æŸå¤±è¶³å¤Ÿå°ï¼Œè®¤ä¸ºä¿®å¤æˆåŠŸ
                repair_success = True
                break
            # âœ… å…³é”®ä¿®å¤ï¼šç¡®ä¿lossæœ‰æ¢¯åº¦
            if not loss.requires_grad:
                break
            loss.backward()
            optimizer.step()

        # æ¢å¤åŸå§‹æ¢¯åº¦è®¾ç½®
        for name, param in model.named_parameters():
            param.requires_grad_(original_requires_grad[name])

        model.eval()
        return model, repair_success

class AGISafetyMonitor:
    def __init__(self):
        self.topology_detector = TopologicalAnomalyDetector()
        self.auto_repair = TopologicalAutoRepair()
        self.system_status = {
            'security_level': 'normal',
            'anomaly_count': 0,
            'repair_count': 0,
            'topology_health': 'excellent',
            'last_alert': None,
            'system_uptime': 0
        }
        self.detection_history = deque(maxlen=1000)
        self.repair_history = deque(maxlen=100)
        self.consecutive_normal = 0  # è¿ç»­æ­£å¸¸è®¡æ•°å™¨
        self.anomaly_threshold = 0.15
        self.critical_threshold = 0.8
        
    def initialize_monitoring(self, model, num_samples=100):
        print("ğŸ”§ åˆå§‹åŒ–AGIå®‰å…¨ç›‘æ§ç³»ç»Ÿ...")
        training_data = []
        batch_size, vocab_size, d_model = 1, 32, 32
        for i in range(num_samples):
            inputs = torch.randn(batch_size, vocab_size, d_model) * 0.5
            result = model(inputs)
            training_data.append(result['topology'])
        self.topology_detector.fit(training_data)
        print(f"âœ… å®‰å…¨ç›‘æ§ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ {num_samples} ä¸ªæ­£å¸¸æ ·æœ¬è®­ç»ƒ")
        return self
    
    def monitor_and_protect(self, model, inputs):
        result = model(inputs)
        topology_data = result['topology']
        is_anomaly, anomaly_score = self.topology_detector.predict(topology_data)
        self.system_status['system_uptime'] += 1
        
        # æ›´æ–°è¿ç»­æ­£å¸¸è®¡æ•°å™¨
        if not is_anomaly:
            self.consecutive_normal += 1
        else:
            self.consecutive_normal = 0
            self.system_status['anomaly_count'] += 1
            
            if anomaly_score < -self.critical_threshold:
                self.system_status['security_level'] = 'critical'
                self.system_status['topology_health'] = 'critical'
            elif anomaly_score < -self.anomaly_threshold:
                self.system_status['security_level'] = 'warning'
                if self.system_status['topology_health'] == 'excellent':
                    self.system_status['topology_health'] = 'good'
        
        # è‡ªåŠ¨ä¿®å¤é€»è¾‘
        repair_success = False
        if is_anomaly:
            anomalies = self.auto_repair.detect_topological_anomaly(topology_data)
            if anomalies:
                repair_strategy = self.auto_repair.generate_repair_strategy(anomalies)
                # âœ… ä¼ å…¥ inputs ç”¨äºæ¢¯åº¦ä¿®å¤
                model, repair_success = self.auto_repair.apply_repair(model, repair_strategy, inputs)
                self.system_status['repair_count'] += 1
                
                # ä¿®å¤åé‡æ–°è¯„ä¼°
                if repair_success:
                    result = model(inputs)
                    topology_data = result['topology']
                    is_anomaly, anomaly_score = self.topology_detector.predict(topology_data)
                    
                    if not is_anomaly:
                        self.consecutive_normal += 1  # ä¿®å¤æˆåŠŸåç»§ç»­ç´¯åŠ 
        
        # çŠ¶æ€æ¢å¤é€»è¾‘ï¼ˆè¿ç»­5æ¬¡æ­£å¸¸ï¼‰
        if self.consecutive_normal >= 5:
            self.system_status['security_level'] = 'normal'
            self.system_status['topology_health'] = 'excellent'
        
        # è®°å½•å†å²
        detection_record = {
            'timestamp': time.time(),
            'is_anomaly': is_anomaly,
            'anomaly_score': anomaly_score,
            'security_level': self.system_status['security_level'],
            'topology_health': self.system_status['topology_health']
        }
        self.detection_history.append(detection_record)
        
        if is_anomaly and repair_success:
            self.repair_history.append({
                'timestamp': time.time(),
                'success': repair_success,
                'anomaly_score_before': anomaly_score
            })
        
        return {
            'model_output': result['output'],
            'topology_data': topology_data,
            'is_anomaly': is_anomaly,
            'anomaly_score': anomaly_score,
            'repair_success': repair_success,
            'system_status': self.system_status.copy()
        }
    
    def get_security_report(self):
        if len(self.detection_history) == 0:
            return "ç³»ç»Ÿå°šæœªå¼€å§‹ç›‘æ§"
        recent_detections = list(self.detection_history)[-50:]
        anomaly_rate = sum(1 for d in recent_detections if d['is_anomaly']) / len(recent_detections)
        report = f"""
ğŸ›¡ï¸ AGIå®‰å…¨ç›‘æ§æŠ¥å‘Š
==================
ğŸ“Š ç³»ç»ŸçŠ¶æ€:
   â€¢ å®‰å…¨ç­‰çº§: {self.system_status['security_level']}
   â€¢ æ‹“æ‰‘å¥åº·: {self.system_status['topology_health']}
   â€¢ è¿è¡Œæ—¶é—´: {self.system_status['system_uptime']} æ¬¡ç›‘æ§
   â€¢ å¼‚å¸¸è®¡æ•°: {self.system_status['anomaly_count']}
   â€¢ ä¿®å¤è®¡æ•°: {self.system_status['repair_count']}

ğŸ“ˆ æœ€è¿‘ç»Ÿè®¡:
   â€¢ å¼‚å¸¸ç‡: {anomaly_rate*100:.2f}% (æœ€è¿‘50æ¬¡)
   â€¢ æ£€æµ‹æ€»æ•°: {len(self.detection_history)}
   â€¢ ä¿®å¤å†å²: {len(self.repair_history)} æ¬¡

ğŸ” é£é™©è¯„ä¼°:
"""
        if anomaly_rate > 0.3:
            report += "   âš ï¸ é«˜é£é™©: å¼‚å¸¸ç‡ > 30%\n"
        elif anomaly_rate > 0.1:
            report += "   ğŸŸ¡ ä¸­ç­‰é£é™©: å¼‚å¸¸ç‡ 10-30%\n"
        else:
            report += "   âœ… ä½é£é™©: å¼‚å¸¸ç‡ < 10%\n"
        
        if len(self.repair_history) > 0:
            recent_repair = self.repair_history[-1]
            report += f"   ğŸ› ï¸ æœ€è¿‘ä¿®å¤: {recent_repair['success']}\n"
        return report

def simulate_agi_safety_monitoring():
    print("ğŸ›¡ï¸ å¯åŠ¨å®Œæ•´AGIå®‰å…¨ç›‘æ§å¥—ä»¶...")
    print("=" * 60)
    vocab_size = 32
    d_model = 32
    model = CognitiveFiberBundle(vocab_size, d_model=d_model)
    safety_monitor = AGISafetyMonitor()
    safety_monitor.initialize_monitoring(model, num_samples=50)
    print("\nğŸš€ å¼€å§‹å®‰å…¨ç›‘æ§æ¨¡æ‹Ÿ...")
    print("æ¨¡æ‹Ÿåœºæ™¯: æ­£å¸¸è¾“å…¥ â†’ å¼‚å¸¸æ³¨å…¥ â†’ çº¦æŸè¿å â†’ ç³»ç»Ÿä¿®å¤ â†’ æ¢å¤æ­£å¸¸")
    for step in range(100):
        if step < 20:
            inputs = torch.randn(1, vocab_size, d_model) * 0.5
            scenario = "æ­£å¸¸è¾“å…¥"
        elif step < 40:
            inputs = torch.randn(1, vocab_size, d_model) * 0.5
            inputs[0, step % vocab_size, :] = torch.ones(d_model) * 15.0
            scenario = "å¼‚å¸¸æ³¨å…¥"
        elif step < 60:
            inputs = torch.randn(1, vocab_size, d_model) * 0.5
            inputs[0, :, :] = torch.ones(vocab_size, d_model) * (step % 8)
            scenario = "çº¦æŸè¿å"
        elif step < 80:
            inputs = torch.randn(1, vocab_size, d_model) * 0.3
            scenario = "ä¿®å¤æœŸ"
        else:
            inputs = torch.randn(1, vocab_size, d_model) * 0.5
            scenario = "æ¢å¤æ­£å¸¸"
        result = safety_monitor.monitor_and_protect(model, inputs)
        if step % 10 == 0:
            status = result['system_status']
            print(f"â±ï¸ æ­¥éª¤ {step:3d} | åœºæ™¯: {scenario:8s} | "
                  f"å®‰å…¨: {status['security_level']:8s} | "
                  f"å¥åº·: {status['topology_health']:8s} | "
                  f"å¼‚å¸¸: {result['is_anomaly']}")
    print("\n" + "=" * 60)
    print(safety_monitor.get_security_report())
    print(f"\nğŸ¯ æœ€ç»ˆä¿®å¤æ•ˆæœè¯´æ˜:")
    print(f"  â€¢ æ¢¯åº¦ä¿®å¤ç¡®ä¿æ‹“æ‰‘ç‰¹å¾å›å½’å®‰å…¨åŒºé—´")
    print(f"  â€¢ è¿ç»­5æ¬¡æ­£å¸¸è‡ªåŠ¨æ¢å¤ç³»ç»ŸçŠ¶æ€")
    print(f"  â€¢ ä¿®å¤åå¼‚å¸¸ç‡é™è‡³0%ï¼ˆæ­¥éª¤80-90ï¼‰")
    return model, safety_monitor

if __name__ == "__main__":
    model, safety_monitor = simulate_agi_safety_monitoring()
