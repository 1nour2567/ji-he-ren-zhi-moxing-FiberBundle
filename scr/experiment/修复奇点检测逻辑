import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

class SparseFiberBundle(nn.Module):
    """ç¨€ç–çº¤ç»´ä¸›è¿‘ä¼¼ç®—æ³• - æ”¯æŒä¸­é—´å±‚ç›‘æ§"""
    def __init__(self, vocab_size, d_model=64, k_neighbors=8):
        super().__init__()
        self.k_neighbors = k_neighbors
        self.d_model = d_model
        self.vocab_size = vocab_size
        
        # å­˜å‚¨ä¸­é—´æ¿€æ´»å€¼ç”¨äºå¥‡ç‚¹æ£€æµ‹
        self.activations = {}
        
        # å‡ ä½•ç¼–ç å±‚
        self.geometric_layers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_model, d_model),
                nn.GELU()
            ),
            nn.Sequential(
                nn.Linear(d_model, d_model),
                nn.GELU()
            )
        ])
    
    def forward(self, x):
        """x: [batch_size, vocab_size, d_model]"""
        batch_size, n, d = x.shape
        x_flat = x.view(-1, d)
        
        # ä¿å­˜è¾“å…¥ç”¨äºå¥‡ç‚¹æ£€æµ‹
        self.activations['input'] = x.clone()
        
        # åº”ç”¨å‡ ä½•å˜æ¢
        for i, layer in enumerate(self.geometric_layers):
            x_flat = layer(x_flat)
            if i == 0:  # ä¿å­˜ç¬¬ä¸€å±‚è¾“å‡º
                self.activations['layer1'] = x_flat.view(batch_size, n, d).clone()
        
        x = x_flat.view(batch_size, n, d)
        self.activations['output'] = x.clone()
        return x

class SingularityDrivenLearner:
    """å¥‡ç‚¹é©±åŠ¨å­¦ä¹ ç®—æ³• - ä¿®æ­£ç‰ˆ"""
    def __init__(self, model):
        self.model = model
        self.singularity_history = []
        self.singularity_threshold = 2.0
    
    def detect_singularity_in_activations(self):
        """åœ¨æ‰€æœ‰æ¿€æ´»å±‚ä¸­æ£€æµ‹å¥‡ç‚¹"""
        detected_singularities = []
        
        for layer_name, activation in self.model.activations.items():
            max_abs = torch.max(torch.abs(activation))
            if max_abs > self.singularity_threshold:
                positions = torch.where(torch.abs(activation) > self.singularity_threshold)
                detected_singularities.append({
                    'layer': layer_name,
                    'detected': True,
                    'type': 'Type_I',
                    'value': max_abs.item(),
                    'positions': positions,
                    'count': len(positions[0])
                })
        
        return detected_singularities
    
    def apply_repair_to_tensor(self, tensor):
        """å¯¹å¼ é‡åº”ç”¨ä¿®å¤ç­–ç•¥"""
        # ç­–ç•¥1: Clampåˆ°åˆç†èŒƒå›´
        repaired = torch.clamp(tensor, -1.0, 1.0)
        return repaired
    
    def train_step_with_proactive_repair(self, batch):
        """ä¸»åŠ¨ä¿®å¤æ¨¡å¼ï¼šåœ¨å‰å‘ä¼ æ’­ä¸­æ£€æµ‹å¹¶ä¿®å¤"""
        # 1. å‰å‘ä¼ æ’­
        outputs = self.model(batch)
        
        # 2. æ£€æµ‹æ‰€æœ‰å±‚çš„å¥‡ç‚¹
        singularities = self.detect_singularity_in_activations()
        
        # 3. å¦‚æœæ£€æµ‹åˆ°å¥‡ç‚¹ï¼Œåº”ç”¨ä¿®å¤
        repaired_outputs = outputs
        if singularities:
            # ä¿®å¤è¾“å‡º
            repaired_outputs = self.apply_repair_to_tensor(outputs)
            
            # è®°å½•å¥‡ç‚¹å†å²
            for sing in singularities:
                self.singularity_history.append(sing)
        
        # 4. è®¡ç®—æŸå¤±
        loss = torch.mean((repaired_outputs - batch) ** 2)
        
        # 5. å¥‡ç‚¹å¥–åŠ±æœºåˆ¶
        if singularities:
            reward = 0.1 * len(singularities)
            loss = loss - reward
        
        return repaired_outputs, loss, singularities

def visualize_singularity_repair_v2():
    """å¯è§†åŒ–å¥‡ç‚¹ä¿®å¤è¿‡ç¨‹ - ä¿®æ­£ç‰ˆ"""
    # æ¨¡æ‹Ÿæ•°æ®
    batch_size = 1
    vocab_size = 20
    d_model = 64
    
    # 1. åˆ›å»ºæ¨¡å‹
    model = SparseFiberBundle(vocab_size, d_model=d_model)
    learner = SingularityDrivenLearner(model)
    
    # 2. åˆ›å»ºåŒ…å«å¼‚å¸¸å€¼çš„è¾“å…¥
    inputs = torch.randn(batch_size, vocab_size, d_model)
    
    # åˆ¶é€ å‡ ä¸ªå¼‚å¸¸å€¼ï¼ˆæ¨¡æ‹Ÿé€»è¾‘çŸ›ç›¾ï¼‰
    inputs[0, 0, 0] = 10.0      # å¼‚å¸¸å€¼1
    inputs[0, 5, 32] = -15.0    # å¼‚å¸¸å€¼2
    inputs[0, 10, 10] = 8.0     # å¼‚å¸¸å€¼3
    inputs[0, 15, 50] = -12.0   # å¼‚å¸¸å€¼4
    
    print("ğŸ” åˆ¶é€ çš„å¼‚å¸¸å€¼ä½ç½®å’Œå€¼:")
    abnormal_positions = [(0,0,0), (0,5,32), (0,10,10), (0,15,50)]
    for pos in abnormal_positions:
        print(f"  ä½ç½® {pos}: {inputs[0, pos[1], pos[2]].item():.2f}")
    
    # 3. ä¸»åŠ¨ä¿®å¤è®­ç»ƒ
    outputs, loss, detected_singularities = learner.train_step_with_proactive_repair(inputs)
    
    # 4. å¯è§†åŒ–å¯¹æ¯”
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # å­å›¾1: è¾“å…¥æ•°æ®åˆ†å¸ƒ
    input_flat = inputs[0].view(-1).detach().numpy()
    axes[0, 0].hist(input_flat, bins=50, alpha=0.7, color='red', edgecolor='black')
    axes[0, 0].set_title('è¾“å…¥æ•°æ®åˆ†å¸ƒ (å«å¼‚å¸¸å€¼)', fontsize=12)
    axes[0, 0].set_xlabel('å€¼')
    axes[0, 0].set_ylabel('é¢‘æ¬¡')
    axes[0, 0].axvline(x=learner.singularity_threshold, color='orange', linestyle='--', label='æ£€æµ‹é˜ˆå€¼')
    axes[0, 0].axvline(x=-learner.singularity_threshold, color='orange', linestyle='--')
    axes[0, 0].legend()
    
    # å­å›¾2: è¾“å‡ºæ•°æ®åˆ†å¸ƒ
    output_flat = outputs[0].view(-1).detach().numpy()
    axes[0, 1].hist(output_flat, bins=50, alpha=0.7, color='blue', edgecolor='black')
    axes[0, 1].set_title('è¾“å‡ºæ•°æ®åˆ†å¸ƒ (ä¿®å¤å)', fontsize=12)
    axes[0, 1].set_xlabel('å€¼')
    axes[0, 1].set_ylabel('é¢‘æ¬¡')
    axes[0, 1].axvline(x=1, color='green', linestyle='--', label='ä¿®å¤è¾¹ç•Œ')
    axes[0, 1].axvline(x=-1, color='green', linestyle='--')
    axes[0, 1].legend()
    
    # å­å›¾3: ä¿®å¤å‰åå¯¹æ¯”
    n_compare = min(100, input_flat.shape[0])
    x_pos = np.arange(n_compare)
    
    axes[1, 0].plot(x_pos, input_flat[:n_compare], 'ro-', alpha=0.6, label='ä¿®å¤å‰', markersize=4)
    axes[1, 0].plot(x_pos, output_flat[:n_compare], 'bo-', alpha=0.6, label='ä¿®å¤å', markersize=4)
    axes[1, 0].set_title('ä¿®å¤å‰åå¯¹æ¯” (å‰100ä¸ªå€¼)', fontsize=12)
    axes[1, 0].set_xlabel('å…ƒç´ ç´¢å¼•')
    axes[1, 0].set_ylabel('å€¼')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # å­å›¾4: å¥‡ç‚¹æ£€æµ‹è¯¦æƒ…
    if detected_singularities:
        layers = [s['layer'] for s in detected_singularities]
        counts = [s['count'] for s in detected_singularities]
        values = [s['value'] for s in detected_singularities]
        
        bar_colors = ['red' if layer == 'input' else 'orange' if layer == 'layer1' else 'purple' 
                     for layer in layers]
        
        bars = axes[1, 1].bar(range(len(layers)), values, color=bar_colors, alpha=0.7)
        axes[1, 1].set_title(f'å„å±‚æ£€æµ‹åˆ°çš„å¥‡ç‚¹ ({len(detected_singularities)}ä¸ª)', fontsize=12)
        axes[1, 1].set_xlabel('ç½‘ç»œå±‚')
        axes[1, 1].set_ylabel('æœ€å¤§å¥‡ç‚¹å€¼')
        axes[1, 1].set_xticks(range(len(layers)))
        axes[1, 1].set_xticklabels(layers, rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars, counts):
            axes[1, 1].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,
                           f'{count}ä¸ª', ha='center', va='bottom', fontsize=10)
    else:
        axes[1, 1].text(0.5, 0.5, 'âœ… æœªæ£€æµ‹åˆ°å¥‡ç‚¹\n(å·²æˆåŠŸä¿®å¤)', 
                       horizontalalignment='center', verticalalignment='center',
                       transform=axes[1, 1].transAxes, fontsize=14)
        axes[1, 1].set_title('å¥‡ç‚¹æ£€æµ‹ç»“æœ', fontsize=12)
    
    plt.tight_layout()
    plt.show()
    
    # æ‰“å°è¯¦ç»†ç»“æœ
    print(f"\nâœ… ä¿®å¤ç»“æœ:")
    print(f"  è®­ç»ƒæŸå¤±: {loss.item():.4f}")
    print(f"  æ£€æµ‹åˆ°å¥‡ç‚¹æ•°é‡: {len(detected_singularities)}")
    
    if detected_singularities:
        print(f"  å¥‡ç‚¹è¯¦æƒ…:")
        for i, sing in enumerate(detected_singularities):
            print(f"    [{i+1}] å±‚: {sing['layer']}, å€¼: {sing['value']:.2f}, æ•°é‡: {sing['count']}ä¸ª")
    
    # éªŒè¯ä¿®å¤æ•ˆæœ
    input_max = torch.max(torch.abs(inputs)).item()
    output_max = torch.max(torch.abs(outputs)).item()
    print(f"  ä¿®å¤å‰æœ€å¤§ç»å¯¹å€¼: {input_max:.2f}")
    print(f"  ä¿®å¤åæœ€å¤§ç»å¯¹å€¼: {output_max:.2f}")
    print(f"  ä¿®å¤æ•ˆæœ: {'âœ… æˆåŠŸ' if output_max <= 1.0 else 'âš ï¸ éƒ¨åˆ†ä¿®å¤'}")

# è¿è¡Œä¿®æ­£ç‰ˆå¯è§†åŒ–
if __name__ == "__main__":
    visualize_singularity_repair_v2()
