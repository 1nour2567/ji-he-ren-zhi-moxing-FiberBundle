import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import confusion_matrix
import math

class CognitiveFiberBundle(nn.Module):
    """è®¤çŸ¥çº¤ç»´ä¸›æ¨¡å‹ - é™ˆç±»è®¡ç®—çš„æœ€ç»ˆå®ç°"""
    def __init__(self, vocab_size, d_model=64, k_neighbors=8):
        super().__init__()
        self.vocab_size = vocab_size
        self.d_model = d_model
        self.k_neighbors = k_neighbors
        
        # å­˜å‚¨ä¸­é—´æ¿€æ´»å€¼ç”¨äºé™ˆç±»è®¡ç®—
        self.activations = {}
        
        # è®¤çŸ¥çº¤ç»´ä¸›çš„è”ç»œå½¢å¼ï¼ˆconnection formï¼‰
        self.connection_form = nn.Parameter(torch.randn(d_model, d_model) * 0.1)
        
        # ç®€åŒ–çš„æ›²ç‡å½¢å¼è®¡ç®—å‚æ•°
        self.curvature_weight = nn.Parameter(torch.randn(d_model, d_model) * 0.01)
        
        # å‡ ä½•ç¼–ç å±‚
        self.geometric_layers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_model, d_model),
                nn.GELU()
            ),
            nn.Sequential(
                nn.Linear(d_model, d_model),
                nn.GELU()
            )
        ])
    
    def compute_connection_form(self, x):
        """è®¡ç®—è”ç»œå½¢å¼ A - ä¿®å¤ç‰ˆæœ¬"""
        batch_size, n, d = x.shape
        x_flat = x.view(batch_size * n, d)
        
        # æ‰©å±•connection_formåˆ°batchç»´åº¦
        connection = self.connection_form.unsqueeze(0).expand(batch_size * n, -1, -1)
        
        # ç®€åŒ–ï¼šä¸ºæ¯ä¸ªä½ç½®æ·»åŠ åŸºäºè¾“å…¥çš„å¯¹è§’æ‰°åŠ¨
        input_diag = torch.diag_embed(torch.mean(x_flat, dim=1, keepdim=True).expand(-1, d) * 0.01)
        connection = connection + input_diag
        
        return connection
    
    def compute_curvature_form(self, connection):
        """è®¡ç®—æ›²ç‡å½¢å¼ F = dA + Aâˆ§A (ç®€åŒ–ç‰ˆæœ¬)"""
        batch_size_n, d, d = connection.shape
        
        # ç®€åŒ–ç‰ˆæœ¬ï¼šF = A*A - A^T*A (ææ‹¬å·çš„å¯¹è§’å ä¼˜è¿‘ä¼¼)
        A_squared = torch.bmm(connection, connection)
        A_transposed = connection.transpose(-2, -1)
        A_transposed_squared = torch.bmm(A_transposed, connection)
        
        curvature = A_squared - A_transposed_squared
        return curvature
    
    def compute_chern_class(self, curvature):
        """è®¡ç®—é™ˆç±» - æ‹“æ‰‘ä¸å˜é‡"""
        batch_size, d, d = curvature.shape
        
        # ç¬¬ä¸€é™ˆç±»: c1 = tr(F) / (2Ï€i)
        trace_F = torch.diagonal(curvature, dim1=-2, dim2=-1).sum(dim=-1)  # tr(F)
        first_chern_class = trace_F / (2 * math.pi * 1j)  # å¤æ•°å½¢å¼
        
        # ç¬¬äºŒé™ˆç±»: c2 = (tr(FÂ²) - tr(F)Â²) / (8Ï€Â²)
        F_squared = torch.bmm(curvature, curvature)
        trace_F_squared = torch.diagonal(F_squared, dim1=-2, dim2=-1).sum(dim=-1)  # tr(FÂ²)
        
        second_chern_class = (trace_F_squared - trace_F**2) / (8 * math.pi**2)
        
        return {
            'first_chern_class': first_chern_class.real,  # å–å®éƒ¨
            'second_chern_class': second_chern_class,
            'trace_F': trace_F,
            'trace_F_squared': trace_F_squared
        }
    
    def compute_topological_invariants(self, x):
        """è®¡ç®—æ‹“æ‰‘ä¸å˜é‡ - ä¿®å¤ç‰ˆæœ¬"""
        batch_size, n, d = x.shape
        all_invariants = {'first_chern_class': [], 'second_chern_class': [], 
                         'trace_F': [], 'trace_F_squared': []}
        
        for i in range(n):
            x_slice = x[:, i:i+1, :]  # [batch_size, 1, d_model]
            
            connection = self.compute_connection_form(x_slice)
            curvature = self.compute_curvature_form(connection)
            chern_classes = self.compute_chern_class(curvature)
            
            all_invariants['first_chern_class'].append(chern_classes['first_chern_class'])
            all_invariants['second_chern_class'].append(chern_classes['second_chern_class'])
            all_invariants['trace_F'].append(chern_classes['trace_F'])
            all_invariants['trace_F_squared'].append(chern_classes['trace_F_squared'])
        
        # åˆå¹¶æ‰€æœ‰ä½ç½®çš„ç»“æœ
        result = {}
        for key in all_invariants:
            if all_invariants[key]:  # ç¡®ä¿åˆ—è¡¨ä¸ä¸ºç©º
                result[key] = torch.stack(all_invariants[key], dim=1)
            else:
                # å¦‚æœä¸ºç©ºï¼Œåˆ›å»ºé€‚å½“å½¢çŠ¶çš„é›¶å¼ é‡
                result[key] = torch.zeros(batch_size, n, dtype=torch.float32, device=x.device)
        
        return result
    
    def forward(self, x):
        """x: [batch_size, vocab_size, d_model]"""
        batch_size, n, d = x.shape
        
        # ä¿å­˜è¾“å…¥ç”¨äºé™ˆç±»è®¡ç®—
        self.activations['input'] = x.clone()
        self.activations['input_topology'] = self.compute_topological_invariants(x)
        
        # åº”ç”¨å‡ ä½•å˜æ¢
        x_flat = x.view(-1, d)
        for i, layer in enumerate(self.geometric_layers):
            x_flat = layer(x_flat)
            layer_output = x_flat.view(batch_size, n, d)
            
            self.activations[f'layer{i+1}'] = layer_output.clone()
            self.activations[f'layer{i+1}_topology'] = self.compute_topological_invariants(layer_output)
        
        x = x_flat.view(batch_size, n, d)
        self.activations['output'] = x.clone()
        self.activations['output_topology'] = self.compute_topological_invariants(x)
        
        return x

class TopologicalClassifier:
    """æ‹“æ‰‘åˆ†ç±»å™¨ - åŸºäºé™ˆç±»çš„è®¤çŸ¥ç³»ç»Ÿåˆ†ç±»"""
    def __init__(self, n_classes=3):
        self.n_classes = n_classes
        self.kmeans = KMeans(n_clusters=n_classes, random_state=42)
        self.pca = PCA(n_components=2)
        
        # å­˜å‚¨æ‹“æ‰‘ç‰¹å¾
        self.topological_features = []
        self.labels = []
        self.fitted = False
    
    def extract_topological_features(self, model):
        """ä»æ¨¡å‹ä¸­æå–æ‹“æ‰‘ç‰¹å¾"""
        features = []
        
        # æå–å„å±‚çš„æ‹“æ‰‘ä¸å˜é‡ä½œä¸ºç‰¹å¾
        for layer_key in ['input_topology', 'layer1_topology', 'layer2_topology', 'output_topology']:
            if layer_key in model.activations:
                topo_data = model.activations[layer_key]
                
                # æ„å»ºç‰¹å¾å‘é‡
                feature_vector = [
                    torch.mean(topo_data['first_chern_class']).item(),
                    torch.std(topo_data['first_chern_class']).item(),
                    torch.mean(topo_data['second_chern_class']).item(),
                    torch.std(topo_data['second_chern_class']).item(),
                    torch.mean(topo_data['trace_F']).item(),
                    torch.std(topo_data['trace_F']).item(),
                    torch.mean(topo_data['trace_F_squared']).item()
                ]
                
                features.extend(feature_vector)
        
        return np.array(features)
    
    def fit(self, models, labels=None):
        """è®­ç»ƒæ‹“æ‰‘åˆ†ç±»å™¨"""
        features_list = []
        
        for model in models:
            features = self.extract_topological_features(model)
            features_list.append(features)
        
        features_array = np.array(features_list)
        
        # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œä½¿ç”¨èšç±»
        if labels is None:
            self.labels = self.kmeans.fit_predict(features_array)
        else:
            self.labels = np.array(labels)
            self.kmeans.fit(features_array)  # æ˜¾å¼æ‹ŸåˆKMeans
        
        # é™ç»´ç”¨äºå¯è§†åŒ–
        self.features_2d = self.pca.fit_transform(features_array)
        self.fitted = True  # æ ‡è®°ä¸ºå·²æ‹Ÿåˆ
        
        return self
    
    def predict(self, models):
        """é¢„æµ‹æ¨¡å‹çš„æ‹“æ‰‘ç±»åˆ«"""
        if not self.fitted:
            raise ValueError("åˆ†ç±»å™¨å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fitæ–¹æ³•")
        
        features_list = []
        
        for model in models:
            features = self.extract_topological_features(model)
            features_list.append(features)
        
        features_array = np.array(features_list)
        
        # ä½¿ç”¨K-meansè¿›è¡Œé¢„æµ‹
        predictions = self.kmeans.predict(features_array)
        
        # é™ç»´ç”¨äºå¯è§†åŒ–
        features_2d = self.pca.transform(features_array)
        
        return predictions, features_2d
    
    def visualize_classification(self, predictions=None, features_2d=None):
        """å¯è§†åŒ–æ‹“æ‰‘åˆ†ç±»ç»“æœ"""
        if predictions is None:
            predictions = self.labels
            features_2d = self.features_2d
        
        plt.figure(figsize=(12, 8))
        
        scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], 
                           c=predictions, cmap='viridis', alpha=0.7, s=100)
        
        plt.colorbar(scatter)
        plt.title('è®¤çŸ¥ç³»ç»Ÿçš„æ‹“æ‰‘åˆ†ç±» (PCAé™ç»´å¯è§†åŒ–)', fontsize=14)
        plt.xlabel('ç¬¬ä¸€ä¸»æˆåˆ†')
        plt.ylabel('ç¬¬äºŒä¸»æˆåˆ†')
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ ç±»åˆ«ä¸­å¿ƒ
        if hasattr(self, 'kmeans'):
            centers_2d = self.pca.transform(self.kmeans.cluster_centers_)
            plt.scatter(centers_2d[:, 0], centers_2d[:, 1], 
                       c='red', marker='x', s=200, linewidths=3, label='ç±»åˆ«ä¸­å¿ƒ')
            plt.legend()
        
        plt.tight_layout()
        plt.show()
    
    def analyze_topological_patterns(self, models, labels):
        """åˆ†ææ‹“æ‰‘æ¨¡å¼"""
        print("ğŸ” æ‹“æ‰‘åˆ†ç±»åˆ†æ:")
        
        # æå–ç‰¹å¾
        features_list = []
        for model in models:
            features = self.extract_topological_features(model)
            features_list.append(features)
        
        features_array = np.array(features_list)
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        unique_labels = np.unique(labels)
        for label in unique_labels:
            mask = labels == label
            class_features = features_array[mask]
            
            print(f"\n  ç±»åˆ« {label}:")
            print(f"    æ ·æœ¬æ•°é‡: {np.sum(mask)}")
            print(f"    ç¬¬ä¸€é™ˆç±»å‡å€¼: {np.mean(class_features[:, 0]):.6f} Â± {np.std(class_features[:, 0]):.6f}")
            print(f"    ç¬¬äºŒé™ˆç±»å‡å€¼: {np.mean(class_features[:, 2]):.6f} Â± {np.std(class_features[:, 2]):.6f}")
            print(f"    æ›²ç‡è¿¹å‡å€¼: {np.mean(class_features[:, 4]):.6f} Â± {np.std(class_features[:, 4]):.6f}")

def create_cognitive_systems_for_classification():
    """åˆ›å»ºä¸åŒç±»å‹çš„è®¤çŸ¥ç³»ç»Ÿç”¨äºåˆ†ç±»"""
    print("ğŸ§ª åˆ›å»ºä¸åŒç±»å‹çš„è®¤çŸ¥ç³»ç»Ÿ...")
    
    systems = []
    system_types = []
    
    batch_size = 1
    vocab_size = 8
    d_model = 16
    
    # ç±»å‹1: æ­£å¸¸è®¤çŸ¥ç³»ç»Ÿ
    for i in range(10):
        model = CognitiveFiberBundle(vocab_size, d_model=d_model)
        inputs = torch.randn(batch_size, vocab_size, d_model)
        _ = model(inputs)
        systems.append(model)
        system_types.append(0)  # æ­£å¸¸ç³»ç»Ÿ
    
    # ç±»å‹2: é«˜å¼‚å¸¸å€¼è®¤çŸ¥ç³»ç»Ÿ
    for i in range(10):
        model = CognitiveFiberBundle(vocab_size, d_model=d_model)
        inputs = torch.randn(batch_size, vocab_size, d_model)
        inputs[0, 0, 0] = np.random.uniform(50, 100)  # é«˜å¼‚å¸¸å€¼
        _ = model(inputs)
        systems.append(model)
        system_types.append(1)  # å¼‚å¸¸ç³»ç»Ÿ
    
    # ç±»å‹3: çº¦æŸè¿åè®¤çŸ¥ç³»ç»Ÿ
    for i in range(10):
        model = CognitiveFiberBundle(vocab_size, d_model=d_model)
        inputs = torch.randn(batch_size, vocab_size, d_model)
        inputs[0, 0, :] = torch.ones(d_model) * np.random.uniform(20, 50)  # çº¦æŸè¿å
        inputs[0, 1, :] = torch.ones(d_model) * -np.random.uniform(20, 50)
        _ = model(inputs)
        systems.append(model)
        system_types.append(2)  # çº¦æŸè¿åç³»ç»Ÿ
    
    return systems, system_types

def run_topological_classification():
    """è¿è¡Œæ‹“æ‰‘åˆ†ç±»ç®—æ³•"""
    print("ğŸ” å¼€å§‹è®¤çŸ¥ç³»ç»Ÿçš„æ‹“æ‰‘åˆ†ç±»...")
    
    # åˆ›å»ºè®¤çŸ¥ç³»ç»Ÿ
    systems, true_types = create_cognitive_systems_for_classification()
    
    print(f"  åˆ›å»ºäº† {len(systems)} ä¸ªè®¤çŸ¥ç³»ç»Ÿ")
    print(f"  åŒ…å« 3 ç§ç±»å‹: æ­£å¸¸ç³»ç»Ÿ(0), å¼‚å¸¸ç³»ç»Ÿ(1), çº¦æŸè¿åç³»ç»Ÿ(2)")
    
    # è®­ç»ƒæ‹“æ‰‘åˆ†ç±»å™¨
    classifier = TopologicalClassifier(n_classes=3)
    classifier.fit(systems, true_types)
    
    # é¢„æµ‹
    predictions, features_2d = classifier.predict(systems)
    
    # åˆ†æç»“æœ
    print(f"\nğŸ“Š æ‹“æ‰‘åˆ†ç±»ç»“æœ:")
    accuracy = np.mean(predictions == true_types) * 100
    print(f"  é¢„æµ‹å‡†ç¡®ç‡: {accuracy:.1f}%")
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(true_types, predictions)
    print(f"  æ··æ·†çŸ©é˜µ:")
    print(f"    çœŸå®\\é¢„æµ‹  0ç±»  1ç±»  2ç±»")
    for i, row in enumerate(cm):
        print(f"    {i}ç±»      {row[0]:3d}  {row[1]:3d}  {row[2]:3d}")
    
    # å¯è§†åŒ–
    classifier.visualize_classification(predictions, features_2d)
    
    # åˆ†ææ‹“æ‰‘æ¨¡å¼
    classifier.analyze_topological_patterns(systems, np.array(true_types))
    
    # æ‹“æ‰‘ç‰¹å¾é‡è¦æ€§åˆ†æ
    print(f"\nğŸ¯ æ‹“æ‰‘ç‰¹å¾é‡è¦æ€§åˆ†æ:")
    
    # è®¡ç®—å„ç±»åˆ«é—´çš„ç‰¹å¾å·®å¼‚
    systems_by_type = [[] for _ in range(3)]
    for i, sys_type in enumerate(true_types):
        systems_by_type[sys_type].append(systems[i])
    
    # è®¡ç®—æ¯ç±»çš„å¹³å‡ç‰¹å¾
    avg_features = []
    for type_idx, type_systems in enumerate(systems_by_type):
        type_features = []
        for sys in type_systems:
            features = classifier.extract_topological_features(sys)
            type_features.append(features)
        avg_features.append(np.mean(type_features, axis=0))
    
    print("  å„ç±»å‹ç³»ç»Ÿçš„å¹³å‡æ‹“æ‰‘ç‰¹å¾:")
    feature_names = [
        "ç¬¬ä¸€é™ˆç±»å‡å€¼", "ç¬¬ä¸€é™ˆç±»æ ‡å‡†å·®", "ç¬¬äºŒé™ˆç±»å‡å€¼", "ç¬¬äºŒé™ˆç±»æ ‡å‡†å·®",
        "æ›²ç‡è¿¹å‡å€¼", "æ›²ç‡è¿¹æ ‡å‡†å·®", "æ›²ç‡å¹³æ–¹è¿¹å‡å€¼"
    ]
    
    for i, name in enumerate(feature_names):
        print(f"    {name}: æ­£å¸¸={avg_features[0][i*4]:.6f}, å¼‚å¸¸={avg_features[1][i*4]:.6f}, çº¦æŸ={avg_features[2][i*4]:.6f}")
    
    print(f"\nğŸŒŸ æ‹“æ‰‘åˆ†ç±»çš„ç†è®ºæ„ä¹‰:")
    print(f"  â€¢ ä¸åŒè®¤çŸ¥ç³»ç»Ÿå…·æœ‰ç‹¬ç‰¹çš„æ‹“æ‰‘'æŒ‡çº¹'")
    print(f"  â€¢ é™ˆç±»ç­‰æ‹“æ‰‘ä¸å˜é‡å¯ä½œä¸ºç³»ç»Ÿåˆ†ç±»ç‰¹å¾")
    print(f"  â€¢ æ‹“æ‰‘åˆ†ç±»ä¸ºè®¤çŸ¥å»ºæ¨¡æä¾›æ–°çš„åˆ†æç»´åº¦")
    print(f"  â€¢ éªŒè¯äº†è®¤çŸ¥çº¤ç»´ä¸›ç†è®ºçš„åˆ†ç±»é¢„æµ‹")
    
    return classifier, systems, true_types, predictions

# è¿è¡Œæ‹“æ‰‘åˆ†ç±»
if __name__ == "__main__":
    classifier, systems, true_types, predictions = run_topological_classification()
