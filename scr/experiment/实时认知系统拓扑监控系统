import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import math
import time
from collections import deque

class CognitiveFiberBundle(nn.Module):
    """è®¤çŸ¥çº¤ç»´ä¸›æ¨¡å‹ - å®æ—¶ç›‘æ§ç‰ˆ"""
    def __init__(self, vocab_size, d_model=64, k_neighbors=8):
        super().__init__()
        self.vocab_size = vocab_size
        self.d_model = d_model
        self.k_neighbors = k_neighbors
        
        # å­˜å‚¨ä¸­é—´æ¿€æ´»å€¼ç”¨äºé™ˆç±»è®¡ç®—
        self.activations = {}
        
        # è®¤çŸ¥çº¤ç»´ä¸›çš„è”ç»œå½¢å¼ï¼ˆconnection formï¼‰
        self.connection_form = nn.Parameter(torch.randn(d_model, d_model) * 0.1)
        
        # ç®€åŒ–çš„æ›²ç‡å½¢å¼è®¡ç®—å‚æ•°
        self.curvature_weight = nn.Parameter(torch.randn(d_model, d_model) * 0.01)
        
        # å‡ ä½•ç¼–ç å±‚
        self.geometric_layers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_model, d_model),
                nn.GELU()
            ),
            nn.Sequential(
                nn.Linear(d_model, d_model),
                nn.GELU()
            )
        ])
    
    def compute_connection_form(self, x):
        """è®¡ç®—è”ç»œå½¢å¼ A - å®æ—¶ç›‘æ§ç‰ˆ"""
        batch_size, n, d = x.shape
        x_flat = x.view(batch_size * n, d)
        
        # æ‰©å±•connection_formåˆ°batchç»´åº¦
        connection = self.connection_form.unsqueeze(0).expand(batch_size * n, -1, -1)
        
        # æ·»åŠ åŸºäºè¾“å…¥çš„éçº¿æ€§é¡¹
        input_effect = torch.einsum('bi,ij->bj', x_flat, self.curvature_weight)
        input_diag = torch.diag_embed(input_effect)
        connection = connection + input_diag * 0.1
        
        return connection
    
    def compute_curvature_form(self, connection):
        """è®¡ç®—æ›²ç‡å½¢å¼ F = dA + Aâˆ§A (å®æ—¶ç›‘æ§ç‰ˆ)"""
        batch_size_n, d, d = connection.shape
        
        # å®æ—¶ç›‘æ§ç‰ˆï¼šF = A*A - A^T*A + éçº¿æ€§é¡¹
        A_squared = torch.bmm(connection, connection)
        A_transposed = connection.transpose(-2, -1)
        A_transposed_squared = torch.bmm(A_transposed, connection)
        
        # æ·»åŠ é«˜é˜¶é¡¹ä»¥å¢å¼ºå·®å¼‚
        A_cubed = torch.bmm(A_squared, connection)
        
        curvature = A_squared - A_transposed_squared + 0.01 * A_cubed
        return curvature
    
    def compute_chern_class(self, curvature):
        """è®¡ç®—é™ˆç±» - å®æ—¶ç›‘æ§ç‰ˆæ‹“æ‰‘ä¸å˜é‡"""
        batch_size, d, d = curvature.shape
        
        # ç¬¬ä¸€é™ˆç±»: c1 = tr(F) / (2Ï€i)
        trace_F = torch.diagonal(curvature, dim1=-2, dim2=-1).sum(dim=-1)  # tr(F)
        first_chern_class = trace_F / (2 * math.pi * 1j)  # å¤æ•°å½¢å¼
        
        # ç¬¬äºŒé™ˆç±»: c2 = (tr(FÂ²) - tr(F)Â²) / (8Ï€Â²)
        F_squared = torch.bmm(curvature, curvature)
        trace_F_squared = torch.diagonal(F_squared, dim1=-2, dim2=-1).sum(dim=-1)  # tr(FÂ²)
        
        second_chern_class = (trace_F_squared - trace_F**2) / (8 * math.pi**2)
        
        return {
            'first_chern_class': first_chern_class.real,  # å–å®éƒ¨
            'second_chern_class': second_chern_class,
            'trace_F': trace_F,
            'trace_F_squared': trace_F_squared,
            'chern_ratio': second_chern_class / (first_chern_class.real + 1e-8),  # é™ˆç±»æ¯”å€¼
            'curvature_norm': torch.norm(curvature, dim=[-2, -1])  # æ›²ç‡èŒƒæ•°
        }
    
    def compute_topological_invariants(self, x):
        """è®¡ç®—æ‹“æ‰‘ä¸å˜é‡ - å®æ—¶ç›‘æ§ç‰ˆ"""
        batch_size, n, d = x.shape
        all_invariants = {
            'first_chern_class': [], 'second_chern_class': [], 
            'trace_F': [], 'trace_F_squared': [],
            'chern_ratio': [], 'curvature_norm': []
        }
        
        for i in range(n):
            x_slice = x[:, i:i+1, :]  # [batch_size, 1, d_model]
            
            connection = self.compute_connection_form(x_slice)
            curvature = self.compute_curvature_form(connection)
            chern_classes = self.compute_chern_class(curvature)
            
            all_invariants['first_chern_class'].append(chern_classes['first_chern_class'])
            all_invariants['second_chern_class'].append(chern_classes['second_chern_class'])
            all_invariants['trace_F'].append(chern_classes['trace_F'])
            all_invariants['trace_F_squared'].append(chern_classes['trace_F_squared'])
            all_invariants['chern_ratio'].append(chern_classes['chern_ratio'])
            all_invariants['curvature_norm'].append(chern_classes['curvature_norm'])
        
        # åˆå¹¶æ‰€æœ‰ä½ç½®çš„ç»“æœ
        result = {}
        for key in all_invariants:
            if all_invariants[key]:  # ç¡®ä¿åˆ—è¡¨ä¸ä¸ºç©º
                result[key] = torch.stack(all_invariants[key], dim=1)
            else:
                # å¦‚æœä¸ºç©ºï¼Œåˆ›å»ºé€‚å½“å½¢çŠ¶çš„é›¶å¼ é‡
                result[key] = torch.zeros(batch_size, n, dtype=torch.float32, device=x.device)
        
        return result
    
    def forward(self, x):
        """x: [batch_size, vocab_size, d_model]"""
        batch_size, n, d = x.shape
        
        # ä¿å­˜è¾“å…¥ç”¨äºé™ˆç±»è®¡ç®—
        self.activations['input'] = x.clone()
        self.activations['input_topology'] = self.compute_topological_invariants(x)
        
        # åº”ç”¨å‡ ä½•å˜æ¢
        x_flat = x.view(-1, d)
        for i, layer in enumerate(self.geometric_layers):
            x_flat = layer(x_flat)
            layer_output = x_flat.view(batch_size, n, d)
            
            self.activations[f'layer{i+1}'] = layer_output.clone()
            self.activations[f'layer{i+1}_topology'] = self.compute_topological_invariants(layer_output)
        
        x = x_flat.view(batch_size, n, d)
        self.activations['output'] = x.clone()
        self.activations['output_topology'] = self.compute_topological_invariants(x)
        
        return x

class RealTimeTopologicalMonitor:
    """å®æ—¶æ‹“æ‰‘ç›‘æ§ç³»ç»Ÿ"""
    def __init__(self, window_size=10):
        self.window_size = window_size
        self.topology_history = deque(maxlen=window_size)
        self.chern_history = deque(maxlen=window_size)
        self.anomaly_history = deque(maxlen=window_size)
        
        # åˆå§‹åŒ–ç»Ÿè®¡é‡
        self.running_mean = None
        self.running_std = None
        
        # ç›‘æ§é˜ˆå€¼
        self.chern_threshold = 0.01  # é™ˆç±»å˜åŒ–é˜ˆå€¼
        self.anomaly_threshold = 0.1  # å¼‚å¸¸æ£€æµ‹é˜ˆå€¼
        
        # åˆ›å»ºå›¾è¡¨
        self.fig, self.axs = plt.subplots(2, 2, figsize=(15, 10))
        self.fig.suptitle('å®æ—¶è®¤çŸ¥ç³»ç»Ÿæ‹“æ‰‘ç›‘æ§', fontsize=16)
        
        # è®¾ç½®å­å›¾
        self.axs[0, 0].set_title('ç¬¬äºŒé™ˆç±»å®æ—¶å˜åŒ–')
        self.axs[0, 1].set_title('æ›²ç‡èŒƒæ•°å®æ—¶å˜åŒ–')
        self.axs[1, 0].set_title('é™ˆç±»æ¯”å€¼å®æ—¶å˜åŒ–')
        self.axs[1, 1].set_title('æ‹“æ‰‘å¼‚å¸¸æ£€æµ‹')
        
        for ax in self.axs.flat:
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ç”¨äºåŠ¨ç”»çš„æ•°æ®
        self.x_data = []
        self.y_data_chern = []
        self.y_data_norm = []
        self.y_data_ratio = []
        self.y_data_anomaly = []
        
        self.time_step = 0
    
    def extract_topological_features(self, model):
        """æå–å®æ—¶æ‹“æ‰‘ç‰¹å¾"""
        features = {}
        
        # è®¡ç®—å„å±‚çš„æ‹“æ‰‘ä¸å˜é‡
        for layer_key in ['input_topology', 'layer1_topology', 'layer2_topology', 'output_topology']:
            if layer_key in model.activations:
                topo_data = model.activations[layer_key]
                
                features[layer_key] = {
                    'first_chern_mean': torch.mean(topo_data['first_chern_class']).item(),
                    'second_chern_mean': torch.mean(topo_data['second_chern_class']).item(),
                    'trace_F_mean': torch.mean(topo_data['trace_F']).item(),
                    'chern_ratio_mean': torch.mean(topo_data['chern_ratio']).item(),
                    'curvature_norm_mean': torch.mean(topo_data['curvature_norm']).item()
                }
        
        return features
    
    def detect_topological_anomaly(self, features):
        """æ£€æµ‹æ‹“æ‰‘å¼‚å¸¸"""
        # è®¡ç®—å½“å‰ç‰¹å¾ä¸å†å²å¹³å‡çš„å·®å¼‚
        if len(self.chern_history) < 2:
            return 0.0  # æ²¡æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
        
        # è®¡ç®—ç¬¬äºŒé™ˆç±»å˜åŒ–
        current_chern = features['output_topology']['second_chern_mean']
        historical_mean = np.mean([h['output_topology']['second_chern_mean'] for h in self.chern_history])
        historical_std = np.std([h['output_topology']['second_chern_mean'] for h in self.chern_history])
        
        if historical_std == 0:
            return 0.0
        
        # æ ‡å‡†åŒ–å·®å¼‚
        chern_deviation = abs(current_chern - historical_mean) / (historical_std + 1e-8)
        
        # è®¡ç®—æ›²ç‡èŒƒæ•°å˜åŒ–
        current_norm = features['output_topology']['curvature_norm_mean']
        historical_norm_mean = np.mean([h['output_topology']['curvature_norm_mean'] for h in self.chern_history])
        historical_norm_std = np.std([h['output_topology']['curvature_norm_mean'] for h in self.chern_history])
        
        if historical_norm_std == 0:
            norm_deviation = 0.0
        else:
            norm_deviation = abs(current_norm - historical_norm_mean) / (historical_norm_std + 1e-8)
        
        # ç»¼åˆå¼‚å¸¸åˆ†æ•°
        anomaly_score = 0.6 * chern_deviation + 0.4 * norm_deviation
        
        return min(anomaly_score, 1.0)  # é™åˆ¶åœ¨0-1èŒƒå›´å†…
    
    def update_monitor(self, model):
        """æ›´æ–°ç›‘æ§ç³»ç»Ÿ"""
        # æå–æ‹“æ‰‘ç‰¹å¾
        features = self.extract_topological_features(model)
        
        # æ£€æµ‹æ‹“æ‰‘å¼‚å¸¸
        anomaly_score = self.detect_topological_anomaly(features)
        
        # ä¿å­˜å†å²æ•°æ®
        self.topology_history.append(features)
        self.chern_history.append(features)
        self.anomaly_history.append(anomaly_score)
        
        # æ›´æ–°ç»Ÿè®¡æ•°æ®
        if len(self.chern_history) > 1:
            all_cherns = [h['output_topology']['second_chern_mean'] for h in self.chern_history]
            self.running_mean = np.mean(all_cherns)
            self.running_std = np.std(all_cherns)
        
        # æ›´æ–°åŠ¨ç”»æ•°æ®
        self.x_data.append(self.time_step)
        self.y_data_chern.append(features['output_topology']['second_chern_mean'])
        self.y_data_norm.append(features['output_topology']['curvature_norm_mean'])
        self.y_data_ratio.append(features['output_topology']['chern_ratio_mean'])
        self.y_data_anomaly.append(anomaly_score)
        
        self.time_step += 1
        
        # é™åˆ¶æ•°æ®æ˜¾ç¤ºé•¿åº¦
        if len(self.x_data) > 20:
            self.x_data = self.x_data[-20:]
            self.y_data_chern = self.y_data_chern[-20:]
            self.y_data_norm = self.y_data_norm[-20:]
            self.y_data_ratio = self.y_data_ratio[-20:]
            self.y_data_anomaly = self.y_data_anomaly[-20:]
        
        # ç»˜åˆ¶å®æ—¶å›¾è¡¨
        self.axs[0, 0].clear()
        self.axs[0, 0].plot(self.x_data, self.y_data_chern, 'b-', linewidth=2, label='ç¬¬äºŒé™ˆç±»')
        self.axs[0, 0].axhline(y=0, color='r', linestyle='--', alpha=0.5, label='é›¶åŸºå‡†')
        self.axs[0, 0].set_title('ç¬¬äºŒé™ˆç±»å®æ—¶å˜åŒ–')
        self.axs[0, 0].grid(True, alpha=0.3)
        self.axs[0, 0].legend()
        
        self.axs[0, 1].clear()
        self.axs[0, 1].plot(self.x_data, self.y_data_norm, 'g-', linewidth=2, label='æ›²ç‡èŒƒæ•°')
        self.axs[0, 1].set_title('æ›²ç‡èŒƒæ•°å®æ—¶å˜åŒ–')
        self.axs[0, 1].grid(True, alpha=0.3)
        self.axs[0, 1].legend()
        
        self.axs[1, 0].clear()
        self.axs[1, 0].plot(self.x_data, self.y_data_ratio, 'm-', linewidth=2, label='é™ˆç±»æ¯”å€¼')
        self.axs[1, 0].set_title('é™ˆç±»æ¯”å€¼å®æ—¶å˜åŒ–')
        self.axs[1, 0].grid(True, alpha=0.3)
        self.axs[1, 0].legend()
        
        self.axs[1, 1].clear()
        self.axs[1, 1].plot(self.x_data, self.y_data_anomaly, 'r-', linewidth=2, label='å¼‚å¸¸åˆ†æ•°')
        self.axs[1, 1].axhline(y=self.anomaly_threshold, color='orange', linestyle='--', 
                              label=f'å¼‚å¸¸é˜ˆå€¼({self.anomaly_threshold})')
        self.axs[1, 1].set_title('æ‹“æ‰‘å¼‚å¸¸æ£€æµ‹')
        self.axs[1, 1].set_ylim(0, 1)
        self.axs[1, 1].grid(True, alpha=0.3)
        self.axs[1, 1].legend()
        
        plt.tight_layout()
        plt.show()
        
        # è¿”å›å½“å‰çŠ¶æ€
        return {
            'second_chern': features['output_topology']['second_chern_mean'],
            'curvature_norm': features['output_topology']['curvature_norm_mean'],
            'chern_ratio': features['output_topology']['chern_ratio_mean'],
            'anomaly_score': anomaly_score,
            'is_anomaly': anomaly_score > self.anomaly_threshold
        }
    
    def get_system_status(self):
        """è·å–ç³»ç»ŸçŠ¶æ€æ‘˜è¦"""
        if len(self.anomaly_history) == 0:
            return "ç³»ç»Ÿåˆå§‹åŒ–ä¸­..."
        
        recent_anomalies = [a for a in list(self.anomaly_history)[-5:] if a > self.anomaly_threshold]
        status = f"æ‹“æ‰‘ç¨³å®šæ€§: {'âœ… ç¨³å®š' if len(recent_anomalies) == 0 else 'âš ï¸ å¼‚å¸¸'}"
        status += f" | æœ€æ–°å¼‚å¸¸åˆ†æ•°: {self.anomaly_history[-1]:.3f}"
        
        if self.running_mean is not None:
            status += f" | ç¬¬äºŒé™ˆç±»å‡å€¼: {self.running_mean:.6f}"
        
        return status

def simulate_real_time_monitoring():
    """æ¨¡æ‹Ÿå®æ—¶æ‹“æ‰‘ç›‘æ§"""
    print("ğŸš¨ å¼€å§‹å®æ—¶è®¤çŸ¥ç³»ç»Ÿæ‹“æ‰‘ç›‘æ§...")
    
    # åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ
    monitor = RealTimeTopologicalMonitor(window_size=10)
    
    batch_size = 1
    vocab_size = 8
    d_model = 16
    
    print("ğŸ§ª å¼€å§‹å®æ—¶ç›‘æ§æ¨¡æ‹Ÿ...")
    print("  æ¨¡æ‹Ÿä¸åŒç±»å‹çš„è¾“å…¥: æ­£å¸¸ â†’ å¼‚å¸¸ â†’ çº¦æŸè¿å â†’ æ¢å¤æ­£å¸¸")
    
    # æ¨¡æ‹Ÿä¸åŒçš„è¾“å…¥ç±»å‹
    for step in range(30):
        # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„è¾“å…¥
        if step < 8:
            # æ­£å¸¸è¾“å…¥
            inputs = torch.randn(batch_size, vocab_size, d_model)
            input_type = "æ­£å¸¸"
        elif step < 16:
            # å¼‚å¸¸è¾“å…¥
            inputs = torch.randn(batch_size, vocab_size, d_model)
            inputs[0, 0, 0] = np.random.uniform(50, 100)  # å¼‚å¸¸å€¼
            input_type = "å¼‚å¸¸"
        elif step < 24:
            # çº¦æŸè¿åè¾“å…¥
            inputs = torch.randn(batch_size, vocab_size, d_model)
            inputs[0, 0, :] = torch.ones(d_model) * np.random.uniform(20, 50)  # çº¦æŸè¿å
            inputs[0, 1, :] = torch.ones(d_model) * -np.random.uniform(20, 50)
            input_type = "çº¦æŸè¿å"
        else:
            # æ¢å¤æ­£å¸¸
            inputs = torch.randn(batch_size, vocab_size, d_model)
            input_type = "æ¢å¤æ­£å¸¸"
        
        # åˆ›å»ºå¹¶è¿è¡Œæ¨¡å‹
        model = CognitiveFiberBundle(vocab_size, d_model=d_model)
        _ = model(inputs)
        
        # æ›´æ–°ç›‘æ§
        status = monitor.update_monitor(model)
        
        # æ‰“å°çŠ¶æ€
        anomaly_status = "ğŸš¨ å¼‚å¸¸" if status['is_anomaly'] else "âœ… æ­£å¸¸"
        print(f"æ­¥éª¤ {step+1:2d}: {input_type:8s} | {anomaly_status} | "
              f"ç¬¬äºŒé™ˆç±»: {status['second_chern']:.6f} | "
              f"å¼‚å¸¸åˆ†æ•°: {status['anomaly_score']:.3f}")
        
        # æ¯5æ­¥æ‰“å°ä¸€æ¬¡ç³»ç»Ÿæ‘˜è¦
        if step % 5 == 4:
            print(f"  ğŸ“Š ç³»ç»Ÿæ‘˜è¦: {monitor.get_system_status()}")
        
        # æ¨¡æ‹Ÿå®æ—¶å»¶è¿Ÿ
        time.sleep(0.1)
    
    print(f"\nğŸ¯ å®æ—¶ç›‘æ§å®Œæˆ!")
    print(f"  ç›‘æ§äº† {30} ä¸ªæ—¶é—´æ­¥")
    print(f"  æ£€æµ‹åˆ°æ‹“æ‰‘å¼‚å¸¸: {sum(1 for a in monitor.anomaly_history if a > monitor.anomaly_threshold)} æ¬¡")
    print(f"  ç³»ç»Ÿç¨³å®šæ€§: {monitor.get_system_status()}")
    
    print(f"\nğŸŒŸ å®æ—¶æ‹“æ‰‘ç›‘æ§çš„ç†è®ºæ„ä¹‰:")
    print(f"  â€¢ å®æ—¶æ£€æµ‹è®¤çŸ¥ç³»ç»Ÿçš„æ‹“æ‰‘å¼‚å¸¸")
    print(f"  â€¢ é‡åŒ–å¼‚å¸¸å¯¹æ‹“æ‰‘ç»“æ„çš„å½±å“")
    print(f"  â€¢ ä¸ºAGIå®‰å…¨æ€§æä¾›å®æ—¶ä¿éšœ")
    print(f"  â€¢ éªŒè¯äº†è®¤çŸ¥çº¤ç»´ä¸›çš„åŠ¨æ€ç‰¹æ€§")
    
    return monitor

# è¿è¡Œå®æ—¶æ‹“æ‰‘ç›‘æ§
if __name__ == "__main__":
    monitor = simulate_real_time_monitoring()
